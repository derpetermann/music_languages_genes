---
title:  |
        | Supporting Information 1: Exploring correlations in genetic and cultural variation across   language families in Northeast Asia 
        |
        | Statistical Analysis in R ^[The R code for this analysis was written by Peter Ranacher, Balthasar Bickel, and Dami√°n E. Blasi]
editor_options:
  chunk_output_type: console
output:
  pdf_document:
    fig_caption: yes
    fig_crop: yes
    latex_engine: xelatex
    keep_tex: true
    number_section: yes
    pandoc_args:
    - --variable=lof
    - --variable=lot
    - --bibliography=genetics.bib
    toc: yes
    toc_depth: 3
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '3'
header-includes:
 - \usepackage[Symbol]{upgreek}
 - \usepackage{tocloft}
 - \settowidth{\cftsubsecnumwidth}{S4.5x}
 - \settowidth{\cftsecnumwidth}{S4.i}
 - \renewcommand{\thefigure}{S\arabic{figure}}
 - \renewcommand{\thetable}{S\arabic{table}}
 - \renewcommand{\thesection}{S\arabic{section}}
---


\clearpage


# Packages and functions

## Packages
For the analysis we use the following three main packages:

  - `ade4` provides tools for multivariate data analysis 
  
  - `adespatial` provides tools for multiscale spatial analysis of multivariate data
  
  - `vegan` provides tools for ordination methods and diversity analysis
  
  - `FactoMinor` provides tools for dimensionality reduction of mixed data (categorical and continuous)
  

```{r load packages, results='hide', message=FALSE, warning=FALSE}

# Data analysis (main)
library(ade4)
library(vegan)
library(adespatial)
library(FactoMineR)

# Data analysis (additional)
library(missMDA)
library(ape)
library(LaplacesDemon)
library(phangorn)

# Data handling and manipulation
library(dendextend)
library(broom)
library(reshape2)
library(plyr)
library(dplyr)
library(usedist)

# Plotting and knitting
library(knitr)
library(kableExtra)
library(ggplot2)
library(ggpolypath)
library(cowplot)
library(ggridges)
library(RColorBrewer)
library(scales)


# Spatial Analysis and mapping
library(sp)
library(spdep)
library(rgdal)
library(rgeos)
library(mapproj)


```

```{r, include=FALSE, cache=F}
knit_hooks$set(crop = hook_pdfcrop, pars = function(before, options, envir) {if(before) {par(family=my_font)} else NULL})


opts_chunk$set(dev = 'cairo_pdf', dev.args=list(bg='transparent'),
               crop=T,
               message = F,
               warning = F,
               cache.comments=T,
               autodep=T,
               pars=T)


my_font <- "sans"
options(width=180, knitr.kable.NA = '', knitr.table.format = "latex")

```

## Functions 

In this section we document all custom-defined functions for performing the redundancy analysis and for data preprocessing. 

### Redundancy Analysis

```{r rdafuns, cache=T}

# Distance-based Moran's Eigenvector (dbMEM) Analysis
random_points_to_dbmem <- function(r_points, print_count=FALSE){
#' Computes dbMEMs for each random point sample in r_points
#' @param r_points: the random points (SpatialPointsDataFrame)
#' @param print_count: Print the number of processed samples when iterating over r_points?
#' @return a list comprising the dbMEMs for each sample
 
  if (class(r_points)[1] != "SpatialPointsDataFrame") {
    stop("please provide a SpatialPointsDataFrame")
  }
  n_sample <- unique(r_points$sample_id)
  #n_sample <- max(r_points$sample_id)
 
  epsilon <- 0.1
  geo_pco  <- list()
 
  for (j in n_sample) {
   
      # Get all points of sample j
      points <- r_points[r_points$sample_id == j,]
 
      # Compute distances between all points in the sample
      mat <- spDists(points, points)

      # Compute the mst, find its longest edge and use as a threshold
      mst_1 <- spantree(mat)
      mst_le <- max(mst_1$dist)
     
      # Add a small epsilon (for numerical stability)
      thresh <- mst_le + epsilon
     
      # Find all nearest neighbors within the distance threshold
      nb <- dnearneigh(points, 0, thresh)
     
      # Normalize the data
      spwt <- lapply(nbdists(nb, points), function(x) 1 - (x/(4 * thresh))^2)
     
      # Compute weighted neighbor list
      lw <- nb2listw(nb, style = "B", glist = spwt, zero.policy = TRUE)
     
      # Compute MEMs with a corresponding positive autocorrelation
      res <- as.data.frame(scores.listw(lw, MEM.autocor = "positive"))
     
      rownames(res) <- points$nam_label
      colnames(res) <- paste("geo_pco_", seq(1,ncol(res)), sep="")
      res <- res[order(rownames(res)), drop = FALSE, ]
      geo_pco[[paste('sample_', j, sep="")]] <- res
     
      if (print_count) {
        if (j%%100 == 0) {
          print(paste(j, " samples processed"))}}}
  return (geo_pco)}

# Redundancy Analysis

rda_wrapper_setup_0 <- function(response, explanatory, n_perm){
#' Performs an RDA without controlling for confounding factors 
#' @param response: the repsonse variable
#' @param explanatory: the explanatory variable 
#' @param n_perm number of permutations for anova-like permutation tes
 
  if (is.null(rownames(response)) & is.null(rownames(explanatory))) {
    stop("Row names of the response and the explanatory variable must be defined!")
  }

  if (any(rownames(response) != rownames(explanatory))) {
    stop("Row names of the response and the
         explanatory variable must be identical and match in order!")
  }
  
  ex_name <- sub('\\_.*', '', colnames(explanatory)[1])
  re_name <- sub('\\_.*', '', colnames(response)[1])
  
  # Run the RDA (in vegan package explanatory variables are Y!)
  rda <- rda(Y = explanatory, X = response)
  
  # Compute the adjusted explained variance and the significance
  r2 <- RsquareAdj(rda)$r.squared
  r2_adj <- RsquareAdj(rda)$adj.r.squared
  sig <- anova.cca(rda, step = n_perm)$`Pr(>F)`[1]
  rda_results <- list(r2=r2, r2_adj=r2_adj, sig=sig,
                      explanatory=ex_name, response=re_name)}

rda_wrapper_setup_1 <- function (response, explanatory, random_geo_pco=NULL,
                                 n_perm=100, print_count=FALSE) {
#' Performs a partial RDA and controls for spatial autocorrelation 
#' @param response: the repsonse variable
#' @param explanatory: the explanatory variable
#' @param random_geo_pco dbMEMs of random spatial point patterns
#' @param n_perm number of permutations per random geo sample
#' @param print_count: print the number of processed samples when iterating over r_points?
#' @return a list comprising the rda results for each sample

  if (is.null(rownames(response)) & is.null(rownames(explanatory))) {
    stop("Row names of the response and the explanatory variable must be defined!")
  }

  if (any(rownames(response) != rownames(explanatory))) {
    stop("Row names of the response and the
         explanatory variable must be identical and match in order!")
  }

  ex_name <- sub('\\_.*', '', colnames(explanatory)[1])
  re_name <- sub('\\_.*', '', colnames(response)[1])

  rda_results <- list()
  progress = 0
  
  for (sample in names(geo_mem)) {
    progress = progress + 1
    constraint <- random_geo_pco[[sample]]
    
    # Run the RDA (in vegan package explanatory variables are Y!)
    rda <- rda(Y = explanatory, X = response, Z = constraint)

    # Compute the (adjusted) explained variance
    r2_res = RsquareAdj2_part(rda)
    r2_semi <- r2_res$r_squared_a
    r2_partial <- r2_res$r_squared_b
    r2_adj_semi <- r2_res$adj_r_squared_a
    r2_adj_partial <- r2_res$adj_r_squared_b

    # Perform permutations
    perm <- permute_rda(n_perm, explanatory, response, constraint)

    rda_results[[sample]] <- list(r2_semi=r2_semi, r2_adj_semi=r2_adj_semi,
                                  r2_partial=r2_partial, r2_adj_partial=r2_adj_partial,
                                  perm_r2_semi=perm$r2_semi,
                                  perm_r2_adj_semi=perm$r2_adj_semi,
                                  perm_r2_partial=perm$r2_partial,
                                  perm_r2_adj_partial=perm$r2_adj_partial,
                                  explanatory=ex_name, response=re_name, geo=TRUE)}
    if (print_count){if (i%%10 == 0) {print(paste(i, " samples processed"))}}
  
  return(rda_results)}

rda_wrapper_setup_2 <- function (response, explanatory, random_geo_pco=NULL,
                                 n_perm=100, print_count=FALSE) {
#' Performs a partial RDA and controls for spatial autocorrelation  and genealogy
#' @param response: the repsonse variable
#' @param explanatory: the explanatory variable
#' @param random_geo_pco dbMEMs of random spatial point patterns
#' @param n_perm number of permutations per random geo sample
#' @param print_count: print the number of processed samples when iterating over r_points?
#' @return a list comprising the rda results for each sample

  if (is.null(rownames(response)) & is.null(rownames(explanatory))) {
    stop("Row names of the response and the explanatory variable must be defined!")
  }

  if (any(rownames(response) != rownames(explanatory))) {
    stop("Row names of the response and the
         explanatory variable must be identical and match in order!")
  }

  ex_name <- sub('\\_.*', '', colnames(explanatory)[1])
  re_name <- sub('\\_.*', '', colnames(response)[1])

  rda_results <- list()
  progress = 0

  for (sample in names(geo_mem)) {
    progress = progress + 1

    constraint <- random_geo_pco[[sample]]

    #  Sample one language from each language family with two members
    sample_lgs <- c(single_lgs, sample(uralic,1), sample(chkkat, 1), sample(tungus, 1))
    explanatory_sample = explanatory[rownames(explanatory) %in% sample_lgs, , drop=F]
    response_sample = response[rownames(response) %in% sample_lgs, , drop=F]
    constraint_sample = constraint[rownames(constraint) %in% sample_lgs, ,drop=F]
    
    # Run the RDA (in vegan package explanatory variables are Y!)
    rda <- rda(Y = explanatory_sample, X = response_sample,
               Z = constraint_sample)

    # Compute the (adjusted) explained variance
    r2_res = RsquareAdj2_part(rda)

    r2_semi <- r2_res$r_squared_a
    r2_partial <- r2_res$r_squared_b
    r2_adj_semi <- r2_res$adj_r_squared_a
    r2_adj_partial <- r2_res$adj_r_squared_b

    # Perform permutations
    perm <- permute_rda(n_perm, explanatory_sample, response_sample, constraint_sample)
    
    rda_results[[sample]] <- list(r2_semi=r2_semi, r2_adj_semi=r2_adj_semi,
                                  r2_partial=r2_partial, r2_adj_partial=r2_adj_partial,
                                  perm_r2_semi=perm$r2_semi,
                                  perm_r2_adj_semi=perm$r2_adj_semi,
                                  perm_r2_partial=perm$r2_partial,
                                  perm_r2_adj_partial=perm$r2_adj_partial,
                                  explanatory=ex_name, response=re_name, geo=TRUE)}
   if (print_count){
    if (i%%100 == 0) {
      print(paste(i, " samples processed"))}}
 return(rda_results)}


rda_wrapper_sensitivity_1 <- function (response, explanatory, random_geo_pco=NULL, exclude_site, 
                                       n_perm=100, print_count=FALSE) {
#' Performs a sensitivity analysis for RDA and controlling for spatial autocorrelation
#' @param response: the repsonse variable
#' @param explanatory: the explanatory variable
#' @param random_geo_pco dbMEMs of random spatial point patterns
#' @param exclude_site Name of the society that is excluded from the analysis
#' @param n_perm number of permutations per random geo sample
#' @param print_count: print the number of processed samples when iterating over r_points?
#' @return a list comprising the rda results for each sample

  if (is.null(rownames(response)) & is.null(rownames(explanatory))) {
    stop("Row names of the response and the explanatory variable must be defined!")
  }

  if (any(rownames(response) != rownames(explanatory))) {
    stop("Row names of the response and the
         explanatory variable must be identical and match in order!")
  }

  ex_name <- sub('\\_.*', '', colnames(explanatory)[1])
  re_name <- sub('\\_.*', '', colnames(response)[1])

  rda_results <- list()
  progress = 0

  for (sample in names(geo_mem)) {
    progress = progress + 1

    constraint <- random_geo_pco[[sample]]
    
    # Exclude one society: the society might hide in each of the families or the isolates
    single_lgs_ex <- single_lgs[single_lgs!=exclude_site]
    uralic_ex <- uralic[uralic!=exclude_site]
    chkkat_ex <- chkkat[chkkat!=exclude_site]
    tungus_ex <- tungus[tungus!=exclude_site]
    
    #  Samples: only use societies that are not excluded
    sample_lgs <- c(single_lgs_ex, uralic_ex, chkkat_ex, tungus_ex)
    explanatory_sample = explanatory[rownames(explanatory) %in% sample_lgs, , drop=F]
    response_sample = response[rownames(response) %in% sample_lgs, , drop=F]
    constraint_sample = constraint[rownames(constraint) %in% sample_lgs, ,drop=F]
    
    # Run the RDA (in vegan package explanatory variables are Y!)
    rda <- rda(Y = explanatory_sample, X = response_sample,
               Z = constraint_sample)

    # Compute the (adjusted) explained variance
    r2_res = RsquareAdj2_part(rda)

    r2_semi <- r2_res$r_squared_a
    r2_partial <- r2_res$r_squared_b
    r2_adj_semi <- r2_res$adj_r_squared_a
    r2_adj_partial <- r2_res$adj_r_squared_b

    # Perform permutations
    perm <- permute_rda(n_perm, explanatory_sample, response_sample, constraint_sample)
    
    rda_results[[sample]] <- list(r2_semi=r2_semi, r2_adj_semi=r2_adj_semi,
                                  r2_partial=r2_partial, r2_adj_partial=r2_adj_partial,
                                  perm_r2_semi=perm$r2_semi,
                                  perm_r2_adj_semi=perm$r2_adj_semi,
                                  perm_r2_partial=perm$r2_partial,
                                  perm_r2_adj_partial=perm$r2_adj_partial,
                                  explanatory=ex_name, response=re_name, 
                                  n_sites=nrow(explanatory_sample))}
   if (print_count){
    if (i%%100 == 0) {
      print(paste(i, " samples processed"))}}
 return(rda_results)}


rda_wrapper_sensitivity_2 <- function (response, explanatory, random_geo_pco=NULL, exclude_site,
                                        n_perm=100, print_count=FALSE) {
#' Performs a sensitvity analysis for partial RDA 
#' controlling for spatial autocorrelation and genealogy
#' @param response: the repsonse variable
#' @param explanatory: the explanatory variable
#' @param random_geo_pco dbMEMs of random spatial point patterns
#' @param exclude_site Name of the society that is excluded from the analysis
#' @param n_perm number of permutations per random geo sample
#' @param print_count: print the number of processed samples when iterating over r_points?
#' @return a list comprising the rda results for each sample

  if (is.null(rownames(response)) & is.null(rownames(explanatory))) {
    stop("Row names of the response and the explanatory variable must be defined!")
  }

  if (any(rownames(response) != rownames(explanatory))) {
    stop("Row names of the response and the
         explanatory variable must be identical and match in order!")
  }

  ex_name <- sub('\\_.*', '', colnames(explanatory)[1])
  re_name <- sub('\\_.*', '', colnames(response)[1])

  rda_results <- list()
  progress = 0

  for (sample in names(geo_mem)) {
    progress = progress + 1

    constraint <- random_geo_pco[[sample]]
    
    # Exclude one society: the society might hide in each of the families or the isolates
    single_lgs_ex <- single_lgs[single_lgs!=exclude_site]
    uralic_ex <- uralic[uralic!=exclude_site]
    chkkat_ex <- chkkat[chkkat!=exclude_site]
    tungus_ex <- tungus[tungus!=exclude_site]
    
    #  Sample one language from each language family with two members
    sample_lgs <- c(single_lgs_ex, sample(uralic_ex,1), sample(chkkat_ex, 1), 
                    sample(tungus_ex, 1))
    explanatory_sample = explanatory[rownames(explanatory) %in% sample_lgs, , drop=F]
    response_sample = response[rownames(response) %in% sample_lgs, , drop=F]
    constraint_sample = constraint[rownames(constraint) %in% sample_lgs, ,drop=F]
    
    # Run the RDA (in vegan package explanatory variables are Y!)
    rda <- rda(Y = explanatory_sample, X = response_sample,
               Z = constraint_sample)

    # Compute the (adjusted) explained variance
    r2_res = RsquareAdj2_part(rda)

    r2_semi <- r2_res$r_squared_a
    r2_partial <- r2_res$r_squared_b
    r2_adj_semi <- r2_res$adj_r_squared_a
    r2_adj_partial <- r2_res$adj_r_squared_b

    # Perform permutations
    perm <- permute_rda(n_perm, explanatory_sample, response_sample, constraint_sample)
    
    rda_results[[sample]] <- list(r2_semi=r2_semi, r2_adj_semi=r2_adj_semi,
                                  r2_partial=r2_partial, r2_adj_partial=r2_adj_partial,
                                  perm_r2_semi=perm$r2_semi,
                                  perm_r2_adj_semi=perm$r2_adj_semi,
                                  perm_r2_partial=perm$r2_partial,
                                  perm_r2_adj_partial=perm$r2_adj_partial,
                                  explanatory=ex_name, response=re_name, 
                                  n_sites=nrow(explanatory_sample))}
   if (print_count){
    if (i%%100 == 0) {
      print(paste(i, " samples processed"))}}
 return(rda_results)}


# Permute RDA
permute_rda <- function(n_perm, explanatory, response, constraint=NULL) {
#' Runs n_perm RDAs with permuted data
#' @param n_perm: the number of permutations
#' @param response: the repsonse variable
#' @param explanatory: the explanatory variable
#' @param constraint the constraint
#' @return a list comprising the RDA results for each permutation

  if (!is.numeric(n_perm)){stop("The number of permutations must
                                be .. well... a number.")}
  permutation_results <- data.frame(r2_adj=rep(NA, n_perm))

  for (i in 1:n_perm){
    # permute the response
    permutation_order <- sample(1:nrow(response))
    response <- response[permutation_order, , drop=F]

    # Geo-constraint?
    # Run the RDA (in vegan package explanatory variables are Y!)
    if (is.null(constraint)) {rda <- rda(Y = explanatory, X = response)}
    else {rda <- rda(Y = explanatory, X = response, Z = constraint)}

     # Compute the (adjusted) explained variance
    r2_res = RsquareAdj2_part(rda)

    r2_semi <- r2_res$r_squared_a
    r2_partial <- r2_res$r_squared_b
    r2_adj_semi <- r2_res$adj_r_squared_a
    r2_adj_partial <- r2_res$adj_r_squared_b

    permutation_results[i, c("r2_semi")] <- r2_semi
    permutation_results[i, c("r2_partial")] <- r2_partial
    permutation_results[i, c("r2_adj_semi")] <- r2_adj_semi
    permutation_results[i, c("r2_adj_partial")] <- r2_adj_partial}

  return(permutation_results)}



# Permute RDA
permute_rda <- function(n_perm, explanatory, response, constraint=NULL) {
#' Runs n_perm RDAs with permuted data
#' @param n_perm: the number of permutations
#' @param response: the repsonse variable
#' @param explanatory: the explanatory variable
#' @param constraint the constraint
#' @return a list comprising the RDA results for each permutation

  if (!is.numeric(n_perm)){stop("The number of permutations must
                                be .. well... a number.")}
  permutation_results <- data.frame(r2_adj=rep(NA, n_perm))

  for (i in 1:n_perm){
    # permute the response
    permutation_order <- sample(1:nrow(response))
    response <- response[permutation_order, , drop=F]

    # Geo-constraint?
    # Run the RDA (in vegan package explanatory variables are Y!)
    if (is.null(constraint)) {rda <- rda(Y = explanatory, X = response)}
    else {rda <- rda(Y = explanatory, X = response, Z = constraint)}

     # Compute the (adjusted) explained variance
    r2_res = RsquareAdj2_part(rda)

    r2_semi <- r2_res$r_squared_a
    r2_partial <- r2_res$r_squared_b
    r2_adj_semi <- r2_res$adj_r_squared_a
    r2_adj_partial <- r2_res$adj_r_squared_b

    permutation_results[i, c("r2_semi")] <- r2_semi
    permutation_results[i, c("r2_partial")] <- r2_partial
    permutation_results[i, c("r2_adj_semi")] <- r2_adj_semi
    permutation_results[i, c("r2_adj_partial")] <- r2_adj_partial}

  return(permutation_results)}

# Compute adjusted R-squared
RsquareAdj2_part <- function (x) {

  #' Computes the (adjusted) R-squared of an RDA model using either
  #' - vegan's semipartial method
  #' - CONOCO's partial method
  #' code adapted from:
  #' https://davidzeleny.net/blog/2016/09/08/adjusted-r2-in-partial-constrained-
  #' ordination-the-difference-between-r-vegan-and-canoco-5/
  #' @param x: RDA result
  #' @return a list comprising the R-squared / adjusted R-squared

  m <- x$CCA$qrank
  n <- nrow(x$CCA$u)
  R2_a <- x$CCA$tot.chi/x$tot.chi
  R2p_a <- x$pCCA$tot.chi/x$tot.chi
  p_a <- x$pCCA$rank
  radj_a <- RsquareAdj(R2_a + R2p_a, n, m + p_a) - RsquareAdj(R2p_a, n, p_a)

  R2_b <- x$CCA$tot.chi/(x$tot.chi - x$pCCA$tot.chi)
  p_b <- x$pCCA$rank
  radj_b <- 1 - (1 - R2_b)*(n - p_b - 1)/(n - m - p_b - 1)

  if (any(na <- m >= n - 1)) radj_b[na] <- NA

  return (list(r_squared_a = R2_a, adj_r_squared_a = radj_a, r_squared_b = R2_b,
               adj_r_squared_b = radj_b))}
```


### Helper functions for data preprocessing
```{r helperfuns, cache=T}

compare_dist = function(d, id1, id2) {
  #' Helper function to normalize distance by range
  #' @param d: the input distance matrix
  #' @param id1: indices specifying the distances to extract.
  #' @param id2: indices specifying the distances to extract.
  round(dist_get(d, id1, id2)/(max(d)-min(d)),2)}


print_dist <- function(d, caption) {
  #' Prints the distance matrices in a table
  #' @param d: the input distance matrix
  #' @param caption: the caption of the table
  d.m <- as.matrix(sort_dist_mat(d))
  d.m[upper.tri(d.m, diag=T)] <- NA	
  colnames(d.m) <- abbreviate(colnames(d.m), minlength=8)
  rownames(d.m) <- abbreviate(rownames(d.m), minlength=8)
  options(knitr.kable.NA = '')
  d.m <- d.m[2:nrow(d.m),1:ncol(d.m)-1]
  
  kable(d.m, digits=3, format = 'latex', caption=caption) %>% 
    kable_styling(latex_options = c("scale_down", "hold_position")) %>% 
                  column_spec(1, border_left=T) %>% 
                  column_spec(ncol(d.m)+1, border_right=T)}


pcos_to_factors <- function(var_th, genetics, genetics_ev, grammar, grammar_ev, 
                            phonology, phonology_ev, music, music_ev, 
                            lexicon, lexicon_ev, geo){
  #' Retains k PCs/PCos which account for at least var_th percent 
  #' of the explained variance 
  #' @param var_th: the variance threshold for each PC/PCo
  #' @param genetics: the PCos for genetics
  #' @param genetics_ev: contains information on the explained variance for genetics
  #' @param grammar: the PCs for grammar
  #' @param grammar_ev: contains information on the explained variance for grammar
  #' @param phonology: the PCs for phonology
  #' @param phonology_ev: contains information on the explained variance for phonology 
  #' @param music: the PCos for music
  #' @param music_ev: contains information on the explained variance for music
  #' @param lexicon: the PCos for lexicon
  #' @param lexicon_ev: contains information on the explained variance for lexicon
  #' @param geo: the dbMEMs
  #' @return a list comprising all factors
  
  genetics_pco_rel <- genetics[, which(genetics_ev >= var_th)]
  grammar_pc_rel <- grammar[, which(grammar_ev >= var_th*100), drop=F]
  phonology_pc_rel <- phonology[, which(phonology_ev >= var_th*100), drop=F]
  music_pco_rel <- music[, which(music_ev >= var_th)]
  lexicon_pco_rel <- lexicon[, which(lexicon_ev >= var_th), drop=F]
  
  factors = list(genetics = genetics_pco_rel[order(rownames(genetics_pco_rel)), ], 
                 music = music_pco_rel[order(rownames(music_pco_rel)), ], 
                 grammar = grammar_pc_rel[order(rownames(grammar_pc_rel)), , drop=F], 
                 phonology = phonology_pc_rel[order(rownames(phonology_pc_rel)), ,drop=F],
                 lexicon = lexicon_pco_rel[order(rownames(lexicon_pco_rel)), ,drop=F],
                 geo = geo)}


get_all_factor_combinations <- function(factor_name){
  #' This helper function create a data frame from all combinations of factor names
  #' @param factor_names: the names of all factors 
  #' @return a data frame with all combinations of factor names
  
  # All possible combinations 
  all_comb <- expand.grid(factor_names, factor_names)
  comb <- all_comb[!all_comb$Var1 == all_comb$Var2, ]
  comb <- as.data.frame(t(comb), stringsAsFactors=FALSE)
  
  return(comb)}

rda_to_correlation_matrix <- function(rda, adjust_significance=TRUE){
  #' This helper function turns the results from an RDA into a correlation matrix
  #' Moreover, it adjusts the significance values using False Discovery Rate (FDR) 
  #' @param rda: the RDA results
  #' @param adjust_significance: Use FDR to adjust significance values?
  
  # Simplify RDA results
  rda_mat <- sapply(rda, function(x){
                  simp <- c(r2=x$r2, r2_adj=x$r2_adj, sig=x$sig, 
                            explanatory=x$explanatory, response=x$response)
                  return(simp)})
  
  rda_mat <- data.frame(t(rda_mat))
  rda_mat <- transform(rda_mat, sig=as.numeric(as.character(sig)), 
             r2=as.numeric(as.character(r2)), r2_adj=as.numeric(as.character(r2_adj)))

  # Adjusting significance (False discovery rate)
  
  if (adjust_significance==T)
    rda_mat$sig <- p.adjust(rda_mat$sig, method = "fdr")

  # Significance
  rda_mat[rda_mat$sig > 0.05, "sig_level"] <- ""
  rda_mat[rda_mat$sig <= 0.01 , "sig_level"] <- "**"
  rda_mat[rda_mat$sig > 0.01 & rda_mat$sig <= 0.05 , "sig_level"] <- "*"

  return(rda_mat)}

partial_rda_to_z_val <- function(rda_result, r2_type) {
  #' Flattens the partial RDA results and computes the z-value for the 
  #' difference between the observed and permuted R-squares.  
  #' Then retrieves the probability density distribution
  #' for both the observed and permuted R-squares. 
  #' @param rda_results: the results from a partial RDA analysis over different paramaters
  #' @param r_2_type: the R-squared type that should be retained (r2_semi, r2_adj_semi,
  #'                  r2_partial, r2_adj_partial)
  #' @param n_lang: include the number of societies in the ouput data frame
  #' @return a list comprising the flattened values, z-standardized values and densities
  
  perm_type = paste("perm_", r2_type, sep="")
  
  # Difference between observed and permuted R-squares
  rda_diff <- lapply(rda_result, function(x)
    unlist(sapply(x, function(y) 
      y[[r2_type]] - mean(y[[perm_type]]))))
  
  rda_diff_df <- ldply(rda_diff, data.frame)
  colnames(rda_diff_df) <- c("Association", "Values")
  
  # Z-normalize difference between permuted and observed R-squares
  rda_diff_z <- lapply(rda_result, function(x)
    unlist(sapply(x, function(y)
    (y[[r2_type]] - mean(y[[perm_type]]))/sd(y[[perm_type]]))))
  
  rda_diff_z_df <- ldply(rda_diff_z, data.frame)
  colnames(rda_diff_z_df) <- c("Association", "z")
  
  # Observed 
  rda_obs <- lapply(rda_result, function(x)
    unlist(sapply(x, function(y)
    y[[r2_type]])))
  
  rda_obs_df <- ldply(rda_diff_z, data.frame)
  colnames(rda_obs_df) <- c("Association", "Values")
  
  # Permuted
  rda_perm <- lapply(rda_result, function(x) 
    unlist(sapply(x, function(y)
      sample(y[[perm_type]], 1))))
  
  rda_perm_df <- ldply(rda_perm, data.frame)
  colnames(rda_perm_df) <- c("Association", "Values")
  
  
  # Probability densities 
  densities <- lapply(names(rda_obs), function(x) {
    
    # Get min and max values for both distributions
    min <- min(c(rda_obs[[x]], rda_perm[[x]]))
    max <- max(c(rda_obs[[x]], rda_perm[[x]]))
    
    # Estimate densities
    obs_d <- density(rda_obs[[x]], bw = "nrd", from=min, to=max)
    perm_d <- density(rda_perm[[x]], bw = "nrd", from=min, to=max)
    
    return (list(observed=obs_d, 
                 permuted=perm_d))})
  
  names(densities) <- names(rda_obs)

  return(list(val=rda_diff_df, z_val=rda_diff_z_df, densities=densities))}


add_proportion_and_kld <- function(rda_flat, diff_th, order_entries=F){
  #' Adds the proportions of samples larger than 0 and 1
  #' and the Kullback Leibler divergence (KLD) to the flattened RDA results
  #' @param rda_flat: the flattened RDA results
  #' @param diff_th: the threshold value
  #' @param order_entries: order the entries according to their KLD
  #' @return a list comprising the flattened rda results (with KLD and proportions)
  #' and a summary of the same results (both are needed for plotting)
  
  # Which proportion of points is larger than zero?
  proportion_pos <- sapply(unique(rda_flat$z_val$Association), function(x) { 
  
    sum(rda_flat$z_val$z[rda_flat$z_val$Association==x] >= 0.0)/
      sum(rda_flat$z_val$Association==x) })
    
  # Which proportion of points is larger than diff_th?
  proportion_th <- sapply(unique(rda_flat$z_val$Association), function(x) { 
  
    sum(rda_flat$z_val$z[rda_flat$z_val$Association==x] >= diff_th)/
      sum(rda_flat$z_val$Association==x) })
  
  # Compute Kullback-Leibler divergence from the observed (px) 
  # to the permuted (py) distribution, if permuted > observed return NA
  
  kld <- sapply(rda_flat$densities, function (a) {
     kld_results <- KLD(px=a[["observed"]]$y,
                        py=a[["permuted"]]$y)
     div_obs_perm <- kld_results$sum.KLD.px.py
     })
  
  kld_disp <- ifelse(proportion_pos > 0.5, kld, NA)
  
  # Add labels (for plotting)
  assoc_labels <- as.vector(sapply(unique(rda_flat$z_val$Association), function (s) {
    s_split <- strsplit(s[1], "_")[[1]]
    s_label <- s_split
    label = paste(s_split[1], "\u2192", s_split[2])}, 
    simplify = TRUE))
  
  summary_df <- data.frame(Association=assoc_labels, 
                           Proportion_pos=proportion_pos,
                           Proportion_th=proportion_th,
                           kld=kld, 
                           kld_disp=kld_disp)
  
  # Add associations, proportions and KLD to flat results (z-normalized/not normalized)
  if (order_entries) {
       order <- rev(order(summary_df$kld_disp, decreasing = T))
  }
  else{
    order <- rev(1:nrow(summary_df))
  }
  summary_df <- summary_df[order, ]
  level_order <- rownames(summary_df)

  # Associations
  rda_flat$val$Association <- factor(rda_flat$val$Association,
      levels=level_order)
  
  rda_flat$z_val$Association <- factor(rda_flat$z_val$Association,
      levels=level_order)
  
  # Proportions larger than zero
  rda_flat$val$prop_pos <- sapply(rda_flat$val$Association, 
                                  function(x) proportion_pos[as.character(x)])
  
  rda_flat$z_val$prop_pos <- rda_flat$val$prop_pos 
  
  # Proportions larger than diff_th
  rda_flat$val$prop_th <-  sapply(rda_flat$val$Association, 
                                  function(x) proportion_th[as.character(x)])
  rda_flat$z_val$prop_th <- rda_flat$val$prop_th
  
  # KLD
  rda_flat$val$kld <-  sapply(rda_flat$val$Association, 
                                  function(x) kld[as.character(x)])
  rda_flat$z_val$kld <- rda_flat$val$kld
  
  # KLD for display in plot
  rda_flat$val$kld_disp <-  sapply(rda_flat$val$Association, 
                                  function(x) kld_disp[as.character(x)])
  rda_flat$z_val$kld_disp <- rda_flat$val$kld_disp
  
  
  return(list(summary = summary_df, rda_df=rda_flat))}


```


```{r plotfuns, cache=T, echo=F}
# Language maps
# Theme
theme_map <- function(...) {
  theme_minimal() +
  theme(
    text = element_text(color = "#22211d", family=my_font),
    axis.line = element_blank(),
    axis.text.x = element_blank(),
    axis.text.y = element_blank(),
    axis.ticks = element_blank(),
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_blank(),
    legend.position ="none",
    plot.title = element_text(color = "black", size = 11),
    plot.background = element_rect(fill = "#f9f9f9", size=1,linetype="solid", 
                                   color="black"), #"#f5f5f2"
    panel.background = element_rect(fill = "#f9f9f9", color = NA), 
    ...)}

# Plot function
plot_language_map <- function(lang_poly, lang_labels_pos, languages,
                              fill.colors=NULL) {
  #' Plots the language polygons
  #' @param lang_poly: the language polygons
  #' @param lang_labels _pos: the geogrpahic positions of the language labels
  #' @param languages: the languages displayed in the map 
  #' @return a ggplot of the map
  
  if(is.null(fill.colors)) {cols <- brewer.pal(length(languages),"Set1")} else {
                       cols <- fill.colors}
                       
  lang_poly <- lang_poly[lang_poly$nam_label %in% languages, ]
  lang_labels <- lang_labels_pos[lang_labels_pos$nam_label %in% languages, ]
  
  gg <- ggplot()
  gg <- gg + coord_map('orthographic',
                       orientation=c(120,0,180),
                       ylim=c(33,80)) 
  gg <- gg + geom_polygon(data=world, aes(x=long, y=lat, group=group), color=NA,
                          fill='lightgrey')
  gg <- gg + geom_polypath(data=lang_poly, aes(x=long, y=lat, 
                           group=group, fill=factor(nam_label)), size=2, colour=NA)
  gg <- gg + geom_point()
  gg <- gg + geom_text(data=lang_labels,
                       aes(x=long, y=lat, label=nam_label, 
                           vjust=-1.1, hjust = .3), size=2)
  gg <- gg + scale_fill_manual(values=cols) #alpha(cols, 0.8))
  gg <- gg + theme_map()
  return(gg)}

# Scree plot 
# Theme
theme_scree <- function(...) {
  theme_minimal() +
  theme(
    text = element_text(color = "#22211d", family=my_font),
    axis.line = element_blank(),
    legend.background = element_rect(fill = "#f5f5f2", color = NA),
    panel.border = element_blank(),
    ...)}

# Plot function 
plot_pc_scree <- function(eigenval, title, type="PC") {
#' Generates scree plots for either the PCs or the PCos
#' @param eigenval: the eigenvalues of the PC(o)
#' @param title: the title of the plot
#' @param type: the type of the plot (either PC or PCo)
#' @return the scree plot (ggplot)

  if (type == "PC") {
    pc_index = seq(1:nrow(eigenval))
    eigenval = data.frame(val = eigenval[, 1], 
                          idx = pc_index,
                          rel = eigenval[, 2],
                          cum = eigenval[, 3])
    pc_legend = "Principal Components"
    subtitle= paste("Explained variance by", pc_legend) 
    pc_labels = paste(rep(c("PC"), nrow(eigenval)), seq(1:nrow(eigenval)))
    ann_offset_y = 6}
  
  else if (type == "PCo"){
    pc_index = seq(1:length(eigenval))
    eigenval = data.frame(val = eigenval, 
                          idx = pc_index,
                          rel = eigenval/sum(eigenval)*100,
                          cum = cumsum(eigenval/sum(eigenval)*100))
    pc_legend = "Principal Coordinates"
    subtitle= paste("Explained variance by", pc_legend) 
    pc_labels = paste(rep(c("PCo"), nrow(eigenval)), seq(1:nrow(eigenval)))
    ann_offset_y = 10}
  
  else stop("Type must be either PC or PCo")
  p <- ggplot(data=eigenval,aes(x=idx, y=rel))
  p <- p + geom_bar(stat="identity")
  p <- p + xlab(pc_legend) + ylab("Eigenvalues (%)")
  p <- p + geom_line(data=eigenval, aes(x=idx, y=cum), colour="orange")
  p <- p + geom_point(data=eigenval, aes(x=idx, y=cum), colour="orange")
  p <- p + scale_x_discrete(limits=pc_labels)
  p <- p + labs(title=title, subtitle=subtitle)
  p <- p + annotate ("label", x = tail(pc_index, n=1)-2.3, 
                     y = tail(eigenval$cum, n=1) - ann_offset_y, 
                     label="Cumulative eigenvalues",
                     colour ="orange", label.size=NA, size=3.5)
  p <- p + theme_scree()
  return(p)}

# Heat maps
# Theme 
theme_heat_maps <- function(...) {
  theme_minimal() +
  theme(
    text = element_text(color = "#22211d", family=my_font),
    legend.background = element_rect(fill = NA, color = NA),
    legend.direction = "horizontal",
    legend.position = "bottom", 
    panel.border = element_blank(),
    panel.grid.major = element_blank(), 
    panel.grid.minor = element_blank(),
    panel.background = element_blank(),
    axis.line = element_blank(),
    axis.title = element_blank(),
    axis.text = element_text(size=15),
    axis.text.x = element_text(vjust = 0, angle = 90, hjust=0),
    plot.margin=unit(c(3,1,1.5,1.2),"cm"),
   
    ...)} 

# Plot function
heat_map_pc <- function(pcs, type="PCo"){
  #' Plots a heat map of the PCs/PCos
  #' @param pcs: the principal components/coordinates
  #' @param type: either PC or PCo
  #' @return the heat map (ggplot)
  
  reorder <- c("Ainu", "Japanese", "Korean", "Buryat", "Even", "Evenki", "Yakut", "Selkup", 
               "Nivkh", "Nganasan", "Chukchi", "Koryak", "Yukagir", "West Greenlandic") 
  pcs <- pcs[reorder, ]

  cnames <- colnames(pcs)
  
  # Normalize the PCs/PCos for each factor 
  pcs_norm <- sapply(cnames, function (y) {
    x <- pcs[, y]
    x_norm <- (x-min(x))/(max(x)-min(x))
    return (x_norm)}, USE.NAMES = T)
  
  if (type == "PC"){
    primary_pc_name <- "PC 1"
    colnames(pcs_norm) <- paste("PC", seq(1, ncol(pcs_norm)))}  
  if (type == "PCo"){
    primary_pc_name <- "PCo 1"
    colnames(pcs_norm) <- paste("PCo", seq(1, ncol(pcs_norm)))}  
  
  rownames(pcs_norm) <- rownames(pcs)
  melted <- melt(pcs_norm)
  
  order_x <- melted %>% 
  filter(Var2 == primary_pc_name) %>% 
  arrange(desc(value)) %>% 
  pull(Var1)
  
  # Create heat map
  h <- ggplot(data = melted, aes(ordered(Var1, levels=order_x), 
                                 ordered(Var2, levels=rev(levels(Var2))), 
                                 fill=value)) 
  
  h <- h + geom_tile(colour="grey")
  h <- h + scale_fill_gradient2(low = "blue", mid = "white", high = "red", 
                                limits = c(0,1), midpoint=0.5, name = NULL)
  h <- h + theme_heat_maps()
  h <- h + coord_fixed()
  h <- h + scale_x_discrete(position = "top") 
  return (h)}  

# Correlation Matrix for RDA
# Theme 
theme_corr_rda <- function(...) {
  theme_minimal() +
  theme(
    text = element_text(family = "Frutiger Light Condensed", color = "#22211d"),
    legend.background = element_rect(fill = NA, color = NA),
    legend.direction = "horizontal",
    legend.position = c(0.2, 1.1), 
    panel.border = element_blank(),
    panel.grid.major = element_blank(), 
    panel.grid.minor = element_blank(),
    panel.background = element_blank(),
    axis.line = element_blank(),
    axis.title = element_text(size = 15, hjust=0.5, vjust=0.4),
    axis.text = element_text(vjust = 1, size = 10),
    plot.margin=unit(c(3,1,1.5,1.2),"cm"),
    ...
  )
} 
# Plot function
plot_rda_as_matrix <- function(rda_matrix){
  #' Plots the results from the redundancy analysis
  #' @param rda_matrix: a matrix comprising the rda results
  #' @return the rda_matrix plot
  c <- ggplot(data = rda_matrix, aes(response, explanatory, fill = r2_adj)) 
  c <- c + geom_tile(color = "white")
  c <- c + scale_fill_gradient(low = "white", high = "red", na.value = "white",
                               limits = c(0,1),
  name=expression(paste("Explained variance \nin response (adjusted ",R^{2},")    ")))
  
  c <- c + geom_text(aes(response, explanatory, 
                         label = paste(round(r2_adj,2), sig_level)), 
                     color = "black", size = 3)

  c <- c + xlab("\nresponse") + ylab("explanatory\n")
  c <- c + theme_corr_rda()
  c <- c + coord_fixed()
  return(c)}

# Density Plots
# Theme
theme_density <- function(...) {
  theme_minimal() +
  theme(
    text = element_text(color = "#22211d", family=my_font),
    legend.background = element_rect(fill = NA, color = NA),
    legend.direction = "horizontal",
    panel.grid.minor = element_blank(),
    panel.background = element_blank(),
    axis.text.y = element_blank(),
    axis.text.x = element_text(angle=90, hjust=0.5, vjust = 0.5, size = 10),
    plot.margin=unit(c(3,1,1.5,1.2),"cm"),
    ...
  )
} 

spatial_density_plot <- function(sp_rda_res, r2_type, difference=FALSE, genealogy=FALSE, 
                                 rda_title="") {
  #' Computes a density plot of the observed and permuted (adjusted) 
  #' R squared for an RDA where space has been partialled out 
  #' @param sp_rda_res: a list comprising the spatial RDA results
  #' @param r2_type: either "r2_semi" or "r2_adj_semi"
  #' @param difference: plot the difference of observed and permuted R squared
  #' @param genealogy: influence of genealogy removed?
  #' @param rda_title: Forplot title: which RDA results are plotted?
  #' @return the density plot  

  if (!r2_type %in% c("r2_partial", "r2_adj_partial")) {
    stop("r2_type must be r2_partial or r2_adj_partial")}
  
  else if (r2_type=="r2_partial"){label="R squared"}
  else if (r2_type=="r2_adj_partial"){label="adjusted R squared"}
  
  ex <- paste(toupper(substr(sp_rda_res[[1]]$explanatory, 1, 1)), 
              substr(sp_rda_res[[1]]$explanatory, 2, 
                     nchar(sp_rda_res[[1]]$explanatory)), sep="")
  
  re <- paste(toupper(substr(sp_rda_res[[1]]$response, 1, 1)), 
              substr(sp_rda_res[[1]]$response, 2, 
                     nchar(sp_rda_res[[1]]$response)), sep="")
  
  
  rda <- sapply(sp_rda_res, function(x) {return (x[[r2_type]])}, simplify=TRUE)
  observed_distr = data.frame(x=na.omit(rda))
  
  perm_rda <- sapply(sapply(sp_rda_res, 
                            function(x) {return (x[paste("perm_", r2_type, sep="")])}, 
                            simplify=TRUE), 
                     function(y) {return (y[1])}, simplify=TRUE)
  
  permuted_distr <- data.frame(x=na.omit(perm_rda))
  
  peak_perm_idx <- which.max(density(permuted_distr$x)$y)
  peak_perm_x <- density(permuted_distr$x)$x[peak_perm_idx]
  peak_perm_y <- density(permuted_distr$x)$y[peak_perm_idx]+0.3
    
  peak_obs_idx <- which.max(density(observed_distr$x)$y)
  peak_obs_x <- density(observed_distr$x)$x[peak_obs_idx]
  peak_obs_y <- density(observed_distr$x)$y[peak_obs_idx]+0.3
  

  s <- ggplot() 
  s <- s + geom_density(data=permuted_distr, aes(x=x), alpha=0.3, colour=NA, fill="blue")
  s <- s + geom_density(data=observed_distr, aes(x=x), alpha=0.3, colour=NA, fill="red")
 
  s <- s + xlab(label) + ylab("Density")
  s <- s + annotate("text", x=peak_obs_x+0.05, y=peak_obs_y, 
                    label="Observed", color="red", size=3)
  s <- s + annotate("text", x=peak_perm_x+0.05, y=peak_perm_y, 
                    label="Random permutations", color="blue", size=3)
  s <- s + labs(title=paste(rda_title, ex, "\u2192", re, sep=" "))
  s <- s + xlim(-1, 1)
  s <- s + theme_density() 
  
  if (!difference) {return(s)}
    
  else {
    diff <- sapply(sapply(sp_rda_res, function(x) {
      return (x[[r2_type]] - x[[paste("perm_", r2_type, sep="")]])}, 
      simplify=TRUE), 
      function(y) {return (y[1])}, simplify=TRUE)
  
    diff_distribution <- data.frame(x=na.omit(diff))

      
    d <- ggplot() 
    d <- d + geom_density(data=diff_distribution, aes(x=x), alpha=0.3, colour=NA, fill="green")
    d <- d + annotate("text", x=peak_obs_x+0.05, y=peak_obs_y+0.2, 
                    label="Observed", color=NA, size=3)
    
    d <- d + annotate("text", x=peak_perm_x+0.05, y=peak_perm_y+0.2, 
                    label="Random permutations", color=NA, size=3)
    d <- d + xlab(paste("Difference of", label, " (observed - random permutations)")) + ylab("Density")
    d <- d + labs(title=paste(rda_title, ex, "\u2192", re, sep=" "))
  
    d <- d + xlim(-1, 1.5) 
    d <- d + theme_density(plot.title = element_text(colour = NA))
    p <- plot_grid(s, d)
    return (p)}}



# Association plot
association_plot_partial <- function (prop, n_sites=NULL, k=F, title=NULL){
  #' Summarizes the observed associations in the partial RDAs in a plot
  #' @param prop: list including the flattened RDA results
  #' @param n_sites: information on the number of societies
  #' @param k: information on k(explained variance per PC/PCo) available?
  #' @param title: Title of the plot
  
  assoc <- as.character(rownames(prop$summary))

  
  if (is.null(n_sites)){
    if (isTRUE(k)){
      assoc_labels <- sapply(assoc, function(s){
      b = paste0("k = ", s)})}
    
    else{
      
      assoc_labels <- sapply(assoc, function(s){
      b = as.character(prop$summary[s, "Association"])
      })}}
    
  else{
    assoc_labels <- sapply(assoc, function(s){
    b = paste(as.character(s), "removed")})
  }
  
  prop_pos_labels <- sapply(assoc, function(s){
    a = prop$summary[s,"Proportion_pos"]
    a = paste0(as.character(format(a * 100, nsmall=1)), "%")})

  prop_th_labels <- sapply(assoc, function(s){
    a = prop$summary[s,"Proportion_th"]
    a = paste0(as.character(format(a * 100, nsmall=1)), "%")})
    
  p <- ggplot(prop$rda_df$z_val, aes(x = z, y=Association, fill=kld_disp)) +
    stat_density_ridges(geom = "density_ridges_gradient", scale=0.6, size=.2) +
    scale_fill_gradient(low = "gray95", high = "black", 
                        na.value="transparent", name = "KLD", 
                        limits = c(0,max(prop$rda_df$z_val$kld_disp))) +
    geom_vline(xintercept = 0, size=.6) +
    geom_vline(xintercept = 1, size=.6, linetype = "dashed") +
    annotate("text", x = 1.4, y = 1.7:(length(prop_th_labels) + 0.7), size=2.5,
             label = prop_th_labels) +
    annotate("text", x = 1.5, y = 0.6, size=3,
             label = expression(P(z > 1)))+
    scale_y_discrete(labels = assoc_labels,  expand = c(0, 1)) +
    xlim(-2, 5) +
    labs(title=title) +
    xlab(expression(paste("Difference between observed and permuted adjusted ", italic(R)^2, 
                          " (z-normalized)"))) + 
    ylab("") + theme(legend.position = "right", plot.title = element_text())
  
  if(!is.null(title)){
    p <- p + ggtitle(as.character(title))
  }
  p
}


# Mapping spatial patterns
map_r2 <- function(sp_rda_res, rand_points, lang_poly, 
                   languages, lang_labels, r2_type, thr, below_thr=T, 
                   lang_color=NULL, title){
#' Plots the spatial locations of models for which removing the effects 
#' of space resulted in a particularily low or high (adjusted) R rsquared
#' @param sp_rda_res: a list comprising the spatial RDA results
#' @param rand_points: all random spatial locations
#' @param lang_poly: the language polygons
#' @param languages: the languages to be displayed in the map
#' @param lang_labels: the language labels
#' @param lang_color: color vector for the languages
#' @param r2_type: r_squared or adjusted r_squared
#' @param thr: the percentile of what qualifies as a low (adjusted) R squared
#' @param below_thr: map the percentile below or above the threshold?
#' @param title: title of the plot
#' @return the plot of the mapped random points 
  
  if(is.null(lang_color)) {lang_color <- factor(nam_label)} else {
    lang_color <- lang_color
  }
  if (!r2_type %in% c("r2_semi", "r2_adj_semi")) {
    stop("r2_type must be r2_semi or r2_adj_semi")}
  
  else if (r2_type=="r2"){label="R squared"}
  else if (r2_type=="r2_adj"){label="Adjusted R squared"}
  
  if (!is.numeric(thr)) {stop("threshold must be numeric")}
  if (!(thr >= 0 &&  thr <=1)) {stop("threshold must be between 0 and 1")}
  
  ex <- paste(toupper(substr(sp_rda_res$sample_1$explanatory, 1, 1)), 
              substr(sp_rda_res$sample_1$explanatory, 2, 
                     nchar(sp_rda_res$sample_1$explanatory)), sep="")
  
  re <- paste(toupper(substr(sp_rda_res$sample_1$response, 1, 1)), 
              substr(sp_rda_res$sample_1$response, 2, 
                     nchar(sp_rda_res$sample_1$response)), sep="")
  
  
  rda <- sapply(sp_rda_res, function(x) {return (x[[r2_type]])}, simplify=TRUE)
  observed_distr = data.frame(x=rda)
  
  # Get samples below threshold 
  ids_to_plot <- sapply(names(sp_rda_res), function(y) {
    
    val <- ecdf(observed_distr$x)(sp_rda_res[[y]][[r2_type]])
    if (below_thr) {
      if (val <= thr) {
        names_samples <- names(sp_rda_res[y][1])
        ids <- sub('.*\\_', '', names_samples)
        return(as.numeric(ids))}}
    else {
      if (val >= thr) {
        names_samples <- names(sp_rda_res[y][1])
        ids <- sub('.*\\_', '', names_samples)
        return(as.numeric(ids))}}})
  
  ids_to_plot <- as.vector(do.call(rbind, ids_to_plot))
  
  # Get locations corresponding to low ids
  points_to_plot <- rand_points[rand_points$sample_id %in% ids_to_plot, ]
  points_to_plot <- points_to_plot[points_to_plot$nam_label %in% languages,  ]
  points_to_plot <- as.data.frame(points_to_plot)
  colnames(points_to_plot) <- c("sample_id", "gid", "nam_label", "long", "lat")
  
  lang_poly <- lang_poly[lang_poly$nam_label %in% languages, ]
  lang_labels <- lang_labels[lang_labels$nam_label %in% languages, ]
  
  # Plot all locations
  cols <- brewer.pal(length(languages),"Set1") 
  
  m <- ggplot()
  m <- m + coord_map('orthographic',
                     orientation=c(120,0,180),
                     ylim=c(33,80)) 
  m <- m + geom_polygon(data=world, aes(x=long, y=lat, group=group), 
                        color=NA, fill='lightgrey')
  m <- m + geom_polypath(data=lang_poly, aes(x=long, y=lat, 
                                         group=group), size=2, colour=NA, fill="darkgrey")
  m <- m + geom_point(data=points_to_plot, aes(x=long, y=lat, 
                                               color=factor(nam_label)), stroke = 0, 
                      alpha=0.7, shape=16, size=1)
  m <- m + scale_color_manual(values=lang_color) #alpha(cols, 1))
  m <- m + geom_text(data=lang_labels,
                       aes(x=long, y=lat, label=nam_label, 
                           vjust=-1.1, hjust = .3), size=2)
  m <- m + labs(title= title)
  m <- m + theme_map()
  return(m)}  


```


# Data 

Our data comprise numerical and categorical variables for grammar and phonology, distance matrices for  genetics, music and lexicon, and the geographical locations of peoples in Northern Asia and Greenland in the form of language polygons. 

## Lexical data
 
We load the lexical distances derived from ASJP data [@ASJP19]. The distances were measured on basis of alignments that were weighted by sound correspondence probabilities estimated by pointwise mutual information (PMI). For details, see Supporting Information: Lexical Distances. 

```{r lex, cache=T}
lexicon <- read.csv('data/lexicon/preprocessed/asjp_dist_pmi.csv', 
                    header=T, row.names = 1)

```


## Genetics and Music

We read the distance matrices for genetics and music. Table S1 shows how these data are matched to unique identifiers in the language data. The UULID concatenates IDs from the ISO 639.3 standard ("i-"), from the AUTOTYP [@AUTOTYP] database ("a-"), and from the GLOTTOLOG [@GLOTTOLOG] catalogue ("g-").

```{r genmusicdata, cache=T}
# Read the gentic data 
genetics <- read.csv("data/genetics/SNPs14PopDist.csv",sep=",", 
                     header=TRUE, row.names=1) 

# Read the music data
music <- read.csv("data/music/Music14PopDist.csv",sep=",",
                  header=TRUE, row.names=1)

```

Table: Music and genome-wide SNP data, with sample sizes, references and match to languages. 

| Population      |  SNPs     | Music | SNP Sources                    | Language                 | UULID             |
|---------------------------------|----------|----------|--------------------------------------------------------|---------------------|-----------------------------|
| Korean       |        6     | 30              | @Lazaridis2014                         | Korean                    | [i-kor][a-141][g-kore1280]  |
| Japanese (Mainland)    | 45  | 30             | @Abecasis2012                          | Japanese                  | [i-jpn][a-118][g-nucl1643]  |
| Ainu (Hokkaido)     | 25    | 30        | @Jinam2012                             | Ainu                      | [i-ain][a-12][g-ainu1240]   |
| Koryak               | 24   | 30           | @Rasmussen2010                         | Koryak                    | [i-kpy][a-1808][g-kory1246] |
| Chukchi               | 20   | 14              | @Lazaridis2014                         | Chukchi                   | [i-ckt][a-56][g-chuk1273]   |
| Yakut              | 21      | 8               | @Lazaridis2014                         | Yakut                     | [i-sah][a-2662][g-yaku1245] |
| Even             | 14        | 17            | @Lazaridis2014, @Fedorova2013           | Even                      | [i-eve][a-738][g-even1260]  |
| Yukagir        | 5          | 12                | @Lazaridis2014                         | Yukagir (Tundra)          | [i-yux][a-2797][g-sout2750] |
| Evenki         | 15           | 28                | @Rasmussen2010                         | Evenki                    | [i-evn][a-527][g-even1259]  |
| Buryat       | 19            | 30            | @Rasmussen2010                         | Buriat                    | [i-bua][a-1095][g-buri1258] |
| West Greenlandic (Inuit)| 5 | 8  | @Rasmussen2010                         | West Greenlandic | [i-kal][a-511][g-kala1399]  |
| Selkup        | 18           | 12           | @Rasmussen2010, @Lazaridis2014          | Selkup                    | [i-sel][a-2393][g-selk1253] |
| Nganasan      | 13           | 15             | @Rasmussen2010                         | Nganasan                 | [i-nio][a-2172][g-ngan1291] |
| Nivkh	        | 15           | 19             | @Fedorova2013, Matsumae et al., this study            | Nivkh                 | [i-niv][a-433][g-gily1242] |
<!-- -->
\normalsize

## Grammar and Phonology


Data on grammar and phonology are aggregated from the following sources:

- AUTOTYP [@AUTOTYP]
- WALS [@WALS], enriched by recodings [@Bickeletal2018Recodings]
- ANU Phonotactics database [@ANU]
- PHOIBLE [@PHOIBLE]

The split into phonology vs. grammar is based on the broad definition in `categorization_of_variables.csv` which includes phonotactic and morphophonological data under phonology.^[Available at  https://github.com/derpetermann/music_languages_genes] 

```{r grammarphondata, cache=T}
# Read the grammar data 
grammar <- read.csv("data/grammar/grammar_var.csv",sep=",", 
                    header=TRUE, row.names=1, stringsAsFactors=T) 

grammar[] <- lapply(grammar, function (x) if (is.logical(x)) {as.factor(x)} else {x}) 
grammar[] <- grammar[-1]

# Read the phonology data
phonology <- read.csv("data/phonology/phon_var.csv",sep=",",
                      header=TRUE, row.names=1, stringsAsFactors=T)

```

## Geographic locations 

The geographical polygon locations of the languages are taken from the Ethnologue [@ethnologue2018]; as there is no polygon for Ainu, we drew one ourselves. We import the language polygons and 15,000 samples of point locations taken randomly from these. The random point samples were generated in PostGIS with the function `ST_GeneratePoints` For further details see the SQL code `generate_random_point_samples.sql` available at https://github.com/derpetermann/music_languages_genes.

```{r polygons, cache=T}
# Fetch the language polygons 
geo_polygons <- readRDS("data/geo/geo_polygons.RDS")

# Fetch random spatial points in the polygons
geo_random_points <- readRDS("data/geo/geo_random_points.RDS")
```

Since the data are gathered from different sources, the names used for the fourteen societies differ. We standardize all names. 

```{r cleanup, cache=T}

# We update all non-matching names using the names in geo_random_points as a template
# Genetics
colnames(genetics)[colnames(genetics) == 'westGreenland'] <- 'West Greenlandic'
rownames(genetics)[rownames(genetics) == 'westGreenland'] <- 'West Greenlandic'
colnames(genetics)[colnames(genetics) == 'Evenk'] <- 'Evenki'
rownames(genetics)[rownames(genetics) == 'Evenk'] <- 'Evenki'

# Music
colnames(music)[colnames(music) == 'WestGreenland'] <- 'West Greenlandic'
rownames(music)[rownames(music) == 'WestGreenland'] <- 'West Greenlandic'
colnames(music)[colnames(music) == 'Nganasa'] <- 'Nganasan'
rownames(music)[rownames(music) == 'Nganasa'] <- 'Nganasan'
colnames(music)[colnames(music) == 'Evenk'] <- 'Evenki'
rownames(music)[rownames(music) == 'Evenk'] <- 'Evenki'

# Lexicon 
colnames(lexicon)[colnames(lexicon) == 'Buriat'] <- 'Buryat'
rownames(lexicon)[rownames(lexicon) == 'Buriat'] <- 'Buryat'
colnames(lexicon)[colnames(lexicon) == 'West_Greenlandic'] <- 'West Greenlandic'
rownames(lexicon)[rownames(lexicon) == 'West_Greenlandic'] <- 'West Greenlandic'

# Grammar
rownames(grammar)[rownames(grammar) == 'Chukchi-Kamchatkan/Chukchi'] <-'Chukchi'
rownames(grammar)[rownames(grammar) == 'Tungusic/Evenki'] <- 'Evenki'
rownames(grammar)[rownames(grammar) == 'Greenlandic Eskimo (West)'] <-'West Greenlandic'
rownames(grammar)[rownames(grammar) == 'Uralic/Selkup'] <- 'Selkup'
rownames(grammar)[rownames(grammar) == 'Yukagir (Tundra)'] <- 'Yukagir'
rownames(grammar)[rownames(grammar) == 'Tungusic/Even'] <- 'Even'
rownames(grammar)[rownames(grammar) == 'Buriat'] <- 'Buryat'
rownames(grammar)[rownames(grammar) == 'Uralic/Nganasan'] <- 'Nganasan'
rownames(grammar)[rownames(grammar) == 'Chukchi-Kamchatkan/Koryak'] <- 'Koryak'

# Phonology 
rownames(phonology)[rownames(phonology) == 'Chukchi-Kamchatkan/Chukchi'] <-'Chukchi'
rownames(phonology)[rownames(phonology) == 'Tungusic/Evenki'] <- 'Evenki'
rownames(phonology)[rownames(phonology) == 'Greenlandic Eskimo (West)'] <-'West Greenlandic'
rownames(phonology)[rownames(phonology) == 'Uralic/Selkup'] <- 'Selkup'
rownames(phonology)[rownames(phonology) == 'Yukagir (Tundra)'] <- 'Yukagir'
rownames(phonology)[rownames(phonology) == 'Tungusic/Even'] <- 'Even'
rownames(phonology)[rownames(phonology) == 'Buriat'] <- 'Buryat'
rownames(phonology)[rownames(phonology) == 'Uralic/Nganasan'] <- 'Nganasan'
rownames(phonology)[rownames(phonology) == 'Chukchi-Kamchatkan/Koryak'] <- 'Koryak'

```

# Dimensionality reduction
  
## Factorial analysis of mixed data (FAMD) of Grammar and Phonology

In view of the fact that the grammar and phonology data are partly numerical and partly categorical, we use a balanced mix of PCA and MCA [@Leetal2008FactoMineR] to bring out the main patterns in the data. Empty values are imputed using the methods developed by @Josseetal2016missMDA. Table 1 in the Supporting Information 2 (Preprocessing: Grammar and Phonology) shows that the coverage is 100% for most languages and never falls below 80%, so only few data points are imputed. 


```{r famd, cache=T}
# Impute empty values
grammar_imputed <- imputeFAMD(grammar)
phonology_imputed <- imputeFAMD(phonology)

# Perform FAMD
grammar_famd <- FAMD(grammar,
                     tab.disj=grammar_imputed$tab.disj,
                     ncp=10,
                     graph=F)

phonology_famd <- FAMD(phonology,
                       ncp=10,
                       tab.disj=phonology_imputed$tab.disj,
                       graph=F)
```

We rescale the dimensions obtained through FAMD in relation to the explained variance:
```{r rescale, cache=T}

for(i in 1:ncol(phonology_famd$ind$coord)) { 
  phonology_famd$ind$coord[,i] <-
    scale(phonology_famd$ind$coord[,i])*
    phonology_famd$eig[i,"percentage of variance"]}

for(i in 1:ncol(grammar_famd$ind$coord)) {
  grammar_famd$ind$coord[,i]<-
    scale(grammar_famd$ind$coord[,i])*
    grammar_famd$eig[i,"percentage of variance"]}
```

## Principal Coordinates Analysis (PCoA) of Lexicon, Music and Genes

We perform a principal coordinate analysis (PCoA) on the distance matrices for genetics and music. Similar to a PCA, a PCoA produces a set of orthogonal axes whose importance is measured by eigenvalues [@dray_2006]. However, in contrast to the PCA, non-Euclidean distance matrices can be used. We correct for negative eigenvalues using the Cailliez procedure.


```{r pcoa, cache=T}

# Convert the matrices into dist objects
lexical_dist <- sort_dist_mat(as.dist(lexicon, diag = FALSE, upper = FALSE))
genetics_dist <- sort_dist_mat(as.dist(genetics, diag = FALSE, upper = FALSE))
music_dist <- sort_dist_mat(as.dist(music, diag = FALSE, upper = FALSE))


# Perform PCoA
lexicon_pcoa <- pcoa(lexical_dist, correction = "cailliez")
genetics_pcoa <- pcoa(genetics_dist, correction = "cailliez")
music_pcoa <- pcoa(music_dist, correction = "cailliez") 
```

We rescale the PCoA components in relation to the explained variance.  

```{r pcoaprep, cache=T}

for(i in 1:ncol(genetics_pcoa$vectors)) { 
genetics_pcoa$vectors[,i] <- scale(genetics_pcoa$vectors[,i])*
  genetics_pcoa$values$Rel_corr_eig[i]}

# Lexcion does not have negative eigenvalues, no correction needed
for(i in 1:ncol(lexicon_pcoa$vectors)) { 
lexicon_pcoa$vectors[,i] <- scale(lexicon_pcoa$vectors[,i])*
  lexicon_pcoa$values$Relative_eig[i]}

for(i in 1:ncol(music_pcoa$vectors)) { 
music_pcoa$vectors[,i] <- scale(music_pcoa$vectors[,i])*
  music_pcoa$values$Rel_corr_eig[i]}
```


## Distance-based Moran's Eigenvector Map Analysis (dbMEM) of the spatial locations

We take 1,000 random point locations from the language polygons (as represented in Figure S1) and compute the spherical distance between them. Then we perform a distance-based Moran's eigenvector map analysis (`dbMEM`) where we decompose the spatial structure of each of the resulting 1,000 distance matrices [@borcard_2002]. Similar to a PCoA, dbMEM reveals the principal coordinates of the spatial locations from which the distance matrix was generated. However, in contrast to PCoA, dbMEM is primarily concerned with the interaction between spatial neighbors. Thus, only distances below a certain threshold feed directly into constructing the principal coordinates, whereas distances above the threshold are "truncated" (i.e. they are set to four times the threshold value). In the dbMEM, we use the length of the longest edge in the minimum spanning tree as a truncation threshold. Moreover, we only return those eigenfunctions that correspond to positive autocorrelation.


```{r map, message=FALSE, warning=FALSE,  fig.width=7, fig.height=6, fig.cap='\\label{fig:map}Geographical locations of the fourteen languages. Language polygons are plotted on two panels because they partly overlap in spatial distributions. Similarly-colored pairs of languages belong to the same family: Even and Evenki belong to the Tungusic family, Selkup and Nganasan to the Uralic family, and Koryak and Chukchi to the Chukotko-Kamchatkan family.', fig.scap='Geographical locations of the fourteen languages', fig.path='figures/', dev='cairo_pdf', echo=F, fig.pos='b', out.extra='', cache=T}

# Convert the SpatialPolygonsDataFrame into a format that ggplot can interpret
row.names(geo_polygons) <- as.character(geo_polygons$gid)
geo_polygons_map <- tidy(geo_polygons)
geo_polygons_map <- merge(geo_polygons_map, geo_polygons@data, by.x="id", by.y="gid")


# Define the position of the language labels in the map
lang_labels <- rbind(c(147, 45, "Ainu"), c(105, 56, "Buryat"), c(-165, 64, "Chukchi"),
                     c(139, 65, "Even"), c(94, 55, "Evenki"), c(136, 28, "Japanese"),
                     c(123, 43, "Korean"), c(170, 57, "Koryak"), c(85, 76, "Nganasan"), 
                     c(145, 54, "Nivkh"),
                     c(-44, 73, "West Greenlandic"), c(80, 55, "Selkup"), 
                     c(123, 75, "Yakut"), c(160, 70, "Yukagir"))

lang_labels <- data.frame(long = as.numeric(lang_labels[, 1]),
                          lat = as.numeric(lang_labels[, 2]),
                          nam_label = lang_labels[, 3])


# Load background map
world = map_data("world")


# The polygons overlap.  We  plot the languages on two separate maps
languages <- c("Ainu", "Buryat", "Chukchi", "Even", "Evenki", "Japanese",
              "Korean", "Koryak", "Nganasan", "Nivkh", "West Greenlandic", "Selkup", 
              "Yakut", "Yukagir")
languages_1 <- c("Nganasan", "Even", "Evenki", "Selkup", "Japanese", "Yukagir", "Nivkh")

languages_2 <- setdiff(languages,languages_1)

colors_1 <- c(Nganasan = '#C13F10', 
              Selkup = '#F56924',
              Even = "#1021CF",
              Evenki = "#6897BB",
              Japanese = '#11C40B',
              Yukagir = '#FF2020',
              Nivkh = '#FFD700')
              
colors_2 <- c(Ainu = '#4BA6DE', 
              Buryat = '#DEC40D',
              Chukchi = "#36A706",
              Koryak = "#1AF0A9",
              Korean = "#D00AC9",
              `West Greenlandic`='#002448',
              Yakut='#DB7811')

loc_1_plot <- plot_language_map(geo_polygons_map, lang_labels, languages_1, fill.colors=colors_1)
loc_2_plot <- plot_language_map(geo_polygons_map, lang_labels, languages_2, fill.colors=colors_2)
locations_plot <- plot_grid(ggplotGrob(loc_1_plot), ggplotGrob(loc_2_plot))
locations_plot
```


```{r dbmem, message=FALSE, warning=FALSE, eval=T, cache=T}

# Some random points are not complete. We remove them.
incomplete_samples <- as.data.frame(geo_random_points) %>% 
  dplyr::group_by(sample_id) %>% 
  dplyr::summarise (n=n()) %>% 
  dplyr::filter(n!=14)

incomplete_samples <- as.vector(incomplete_samples$sample_id)
geo_random_points <- geo_random_points[!geo_random_points$sample_id 
                                       %in% incomplete_samples, ]

# We take 1000 samples from the random points and compute dbMEMs for each sample
n_geo_samples = 1000
choose_p <- sample(unique(geo_random_points$sample_id), n_geo_samples, replace=F)
geo_mem <- random_points_to_dbmem(geo_random_points[geo_random_points$sample_id 
                                                    %in% choose_p, ])
```


## Visualizing the explained variance

We visualize the results of the PCA and PCoA in a scree plot. The figures below show the fraction of total variance in the data as explained by each PC/PCo in decreasing order. We extract the eigenvalues from the PCos/PCs and visualize the explained variance.

```{r screegenetics, fig.cap='Scree plot of explained variance for Genetics', fig.path='figures/', dev='cairo_pdf', echo=F, cache=T, fig.width=8, out.extra=''}

# Extract eigenvalues from PC/PCo results 
genetics_ev <- genetics_pcoa$values$Corr_eig
music_ev <- music_pcoa$values$Corr_eig
# Lexcion does not have negative eigenvalues, no correctes eigenvalues needed
lexicon_ev <- lexicon_pcoa$values$Eigenvalues
grammar_ev <- grammar_famd$eig
phonology_ev <- phonology_famd$eig

# Generate Scree plots 
plot_pc_scree(eigenval=genetics_ev, title="Genetics", type="PCo")

```

```{r screemusic, fig.cap='Scree plot of explained variance for Music', fig.path='figures/', dev='cairo_pdf', fig.width=7, cache=T, echo=F}
plot_pc_scree(eigenval=music_ev, title="Music", type="PCo")
```

```{r screelexicon, fig.cap='Scree plot of explained variance for Lexicon', fig.path='figures/', dev='cairo_pdf', fig.width=7, cache=T, echo=F}
plot_pc_scree(eigenval=lexicon_ev, title="Lexicon", type="PCo")
```

```{r screegrammar,  fig.cap='Scree plot of explained variance for Grammar', fig.path='figures/', fig.width=7, dev='cairo_pdf', cache=T, echo=F}
plot_pc_scree(eigenval=grammar_ev, title="Grammar", type="PC")
```

```{r screephon, fig.cap='Scree plot of explained variance for Phonology', fig.path='figures/', fig.width=7, dev='cairo_pdf', cache=T, echo=F}
plot_pc_scree(eigenval=phonology_ev, title="Phonology", type="PC")
```

\clearpage


## Heatmaps of PCs and PCos 

We extract the principal components/coordinates for all factors: genetics, grammar, music and phonology. We normalize the PCs/PCos to a range from 0 to 1 and then plot a heatmap for each factor. 

```{r merge, cache=T}

# Extract the PCs and the PCos from the PCA and PCoA results
genetics_pco <- genetics_pcoa$vectors
music_pco <- music_pcoa$vectors
lexicon_pco <- lexicon_pcoa$vectors
grammar_pc <- grammar_famd$ind$coord
phonology_pc <- phonology_famd$ind$coord 

# Change the column names of all PCs and PCoAs  
colnames(genetics_pco)<- paste("genetics_pco_", seq(1,ncol(genetics_pco)), sep="")
colnames(music_pco) <- paste("music_pco_", seq(1,ncol(music_pco)), sep="")
colnames(lexicon_pco) <- paste("lexicon_pco_", seq(1,ncol(lexicon_pco)), sep="")
colnames(grammar_pc) <- paste("grammar_pc_", seq(1,ncol(grammar_pc)), sep="")
colnames(phonology_pc) <- paste("phonology_pc_", seq(1,ncol(phonology_pc)), sep="")

```


```{r heatgenetics, fig.cap='Heat plot of the first nine PCos (normalized) of Genetics', fig.path='figures/', dev='cairo_pdf', fig.width=7, fig.height=6, echo=F, fig.pos='H', cache=T, out.extra='', out.width='.99\\linewidth', fig.align="center"}
heat_map_pc(genetics_pco, type="PCo")
```


```{r heatmusic, fig.cap='Heat plot of the first six PCos (normalized) of Music', fig.path='figures/', dev='cairo_pdf', fig.width=6, fig.height=6, cache=T, echo=F, out.extra='', out.width='.7\\linewidth', fig.align="center"}
heat_map_pc(music_pco, type="PCo")
```


```{r heatlexcion, fig.cap='Heat plot of the first ten PCos (normalized) of Lexicon', fig.path='figures/', dev='cairo_pdf', fig.width=7, fig.height=7, cache=T, echo=F, out.extra='', out.width='.7\\linewidth', fig.align="center"}
heat_map_pc(lexicon_pco[, c(1:10)], type="PCo")
```

```{r heat_map_grammar, fig.cap='Heat plot of the first ten PCs (normalized) of Grammar', fig.path='figures/', dev='cairo_pdf', fig.width=7, fig.height=7, cache=T, echo=F, out.extra='', out.width='.7\\linewidth', fig.align="center"}
heat_map_pc(grammar_pc, type="PC")
```


```{r heatphon, fig.cap='Heat plot of the first ten PCs (normalized) of Phonology', fig.path='figures/', dev='cairo_pdf', fig.width=7, fig.height=7, cache=T, echo=F, out.extra='', out.width='.7\\linewidth', fig.align="center"}
heat_map_pc(phonology_pc, type="PC")
```

\clearpage

# Distance visualization (NeighborNets)

We compute Euclidean distance matrices from the dimensionality-reduced data and create NeighborNets in SplitsTree [@huson2006application]. 


```{r dists, cache=T, echo=F}
dist_list <- lapply(list(genetics=genetics_pco, 
                         music=music_pco, 
                         lexicon=lexicon_pco,
                         grammar=grammar_pc, 
                         phonology=phonology_pc), 
                    function(f) {dist(f)})

```

```{r lexicaldist, fig.cap='Lexical (ASJP) distances', echo=F, fig.align="center", fig.pos='H', cache=F, fig.width=14, fig.height=16, out.extra='', out.width='.6\\linewidth'}
print_dist(dist_list$lexicon, 'Lexical distances')
include_graphics("neighbournets/lex.png")
```

\clearpage


```{r gendist, fig.cap='Genetic distances', echo=F, fig.pos='H', fig.align="center", cache=F, fig.width=14, fig.height=16, out.width='.99\\linewidth', out.extra='', fig.path='figures/'}
print_dist(dist_list$genetics, 'Genetic distances')
knitr::include_graphics("neighbournets/gen.png")
```
\clearpage

```{r musicdist, fig.cap='Music distances', echo=F, fig.pos='H', fig.align="center",  cache=F, fig.width=14, fig.height=16, out.extra='', fig.path='figures/', out.width='.8\\linewidth'}
print_dist(dist_list$music, 'Music distances')
knitr::include_graphics("neighbournets/mus.png")
```
\clearpage

```{r gramdist, fig.cap='Grammar distances (scaled)', echo=F, fig.align="center", fig.pos='H', cache=F, fig.width=14, fig.height=16, fig.path='figures/', out.extra='', out.width='.99\\linewidth'}
print_dist(dist_list$grammar, 'Grammar distances')
knitr::include_graphics("neighbournets/gramm.png")
```
\clearpage

```{r phondist, fig.cap='Phonology distances (scaled)', echo=F, fig.pos='H', cache=F, fig.width=14, fig.height=16, out.extra='', fig.align="center", out.width='.99\\linewidth', fig.path='figures/'}
print_dist(dist_list$phonology, 'Phonology distances')
knitr::include_graphics("neighbournets/phon.png")
```


\clearpage 

## Comparing invidivdal distances

The NeighborNets visually suggest some potential cases where the distance between related societies is smaller than the distance to their next unrelated society. To evaluate this formally we compare distances between pairs of languages within families ($d_\text{fam}$) against distances between one of these languages to their next unrelated neighbor ($d_\text{nun}$). We normalize the distances by dividing them by the difference between the maximal and the minimal distance in a given dataset (see the definition of the `compare_dist` function on page 12). In what follows we report $d_\text{fam}$ and $d_\text{nun}$ for those related languages that occur next to each other in the neighbornets. These related languages are potential candidates for $d_\text{fam} < d_\text{nun}$ potentially showing an effect of language families on distances.

&nbsp;

**Genetics** 

```{r distcompare gen}
d_fam_chukotko_gen <- compare_dist(dist_list$genetics, "Chukchi", "Koryak")
d_nun_chukotko_gen <- compare_dist(dist_list$genetics, "Chukchi", "West Greenlandic")

d_fam_uralic_gen <- compare_dist(dist_list$genetics, "Nganasan", "Selkup")
d_nun_uralic_gen <- compare_dist(dist_list$genetics, "Nganasan", "Yukagir")

```
&nbsp;

In Chukotko-Kamchatkan:\
$d_\text{fam} =$ `r d_fam_chukotko_gen`  vs. $d_\text{nun} =$ `r d_nun_chukotko_gen`.\
&nbsp;

In Uralic:\
$d_\text{fam} =$ `r d_fam_uralic_gen`  vs. $d_\text{nun} =$ `r d_nun_uralic_gen`.\
&nbsp;


**Grammar** 

```{r distcompare grammar}

d_fam_tungusic_gram <-  compare_dist(dist_list$grammar, "Even", "Evenki")
d_nun_tungusic_gram <- compare_dist(dist_list$grammar, "Even", "Nivkh")

d_fam_uralic_gram <- compare_dist(dist_list$grammar, "Selkup", "Nganasan")
d_nun_uralic_gram <- compare_dist(dist_list$grammar, "Selkup", "Buryat")

d_fam_chukotko_gram <- compare_dist(dist_list$grammar, "Koryak", "Chukchi")
d_nun_chukotko_gram <- compare_dist(dist_list$grammar, "Koryak", "Yakut")

```
&nbsp;

In Tungusic:\
$d_\text{fam} =$ `r d_fam_tungusic_gram`  vs. $d_\text{nun} =$ `r d_nun_tungusic_gram`.\
&nbsp;  

In Chukotko-Kamchatkan:\
$d_\text{fam} =$ `r d_fam_chukotko_gram`  vs. $d_\text{nun} =$ `r d_nun_chukotko_gram`.\
&nbsp;

In Uralic:\
$d_\text{fam} =$ `r d_fam_uralic_gram`  vs. $d_\text{nun} =$ `r d_nun_uralic_gram`.\
&nbsp;


**Phonology**

```{r distcompare phonology}

d_fam_chukotko_phon <- compare_dist(dist_list$phonology, "Chukchi", "Koryak")

# Visully, both Ainu and Nganasan appear to have two equally close
# neighbours, we compute the distance to both and pick the minimum
d_nun_chukotko_phon_1 <- compare_dist(dist_list$phonology, "Chukchi", "Ainu")
d_nun_chukotko_phon_2 <- compare_dist(dist_list$phonology, "Koryak", "Nganasan")
```
&nbsp;

In Chukotko-Kamchatkan:\
$d_\text{fam} =$ `r d_fam_chukotko_phon`  vs. $d_\text{nun} =$ `r min(d_nun_chukotko_phon_1, d_nun_chukotko_phon_2)`  

\clearpage


# Redundancy Analysis (RDA)

Redundancy Analysis (RDA) extracts the variation in a set of response variables that can be explained by a set of explanatory variables  [@legendre_2012]. In our case the response and explanatory variables comprise the principle components (coordinates) of a factor, e.g. the explanatory variable comprises the PCs of grammar and the response those of phonology. RDA carries out a multiresponse multiple linear regression, that is a regression of multiple response variables on multiple explanatory variables [@van_den_wollenberg_1977]. We perform RDA for three different setups and report the associations found in the data:

\begin{itemize}
  \item {\textbf{Setup 0: RDA:} In this setup we do not control for potential confounding factors.}
  \item {\textbf{Setup 1: Partial RDA controlling for spatial autocorrelation:} In this setup we account for the influence of space. We take random point locations from the language polygons in turn and partial out their effect on the response before running the RDA. Thus, we explore to what degree the associations are affected by different spatial neighborhood scenarios.}
  \item {\textbf{Setup 2: Partial RDA controlling for spatial autocorrelation and genealogy}: In addition to spatial neighborhood we also control for genealogy. We perform a partial RDA for random samples of non-related languages only and explore to what degree the associations are driven by phylogenetic inheritance.}
\end{itemize}

For each setup we report the observed explained variance (adjusted $R^2$) and compare it to the explained variance of random permutations. For associations with non-random, consistently high explained variance, we perform three types of sensitivity analysis to explore how changes in the model affect the results: 

\begin{itemize}
  \item {\textbf{Sensitivity 1: Influence of Principal components/coordinates} Given the small number of observations (fourteen societies) using all principal components/coordinates would yield an over-determined model. Hence, we only retain those PCs/PCos per factor which account for at least $k\%$ of the explained variance. We run the partial RDA with different values for $k$ and compare the results. }
  \item {\textbf{Sensitivity 2: Influence of sampling} Some societies might have a larger contribution to the associations than others. We exclude each society in turn and run a partial RDA to explore the influence of each society on the associations.}
  \item {\textbf{Sensitivity 3: Spatial distribution of $R^2$} We explore the spatial locations of samples for which the adjusted $R^2$ is particularly low/high. If locations with low and high (adjusted) $R^2$ differ in space, this might indicate that a particular neighborhood scenario (low $R^2$) explains the variance in the response, while another one does not (high $R^2$).}
\end{itemize}


## RDA with different setups

Before the analysis, we match the order of societies for each factor and combine all factors in a list. We find all combinations of factors by expanding the factor names to a grid. We iterate over this grid, such that each of factor once functions as a predictor and once as a response in the RDA.

```{r retain, eval=T, cache=T}
# Retain PCs/PCos
factors <- pcos_to_factors(var_th=0.15, 
                           genetics=genetics_pco, 
                           genetics_ev=genetics_pcoa$values$Rel_corr_eig,
                           grammar=grammar_pc, grammar_ev=grammar_famd$eig[, 2], 
                           phonology=phonology_pc, phonology_ev=phonology_famd$eig[, 2], 
                           music=music_pco, music_ev=music_pcoa$values$Rel_corr_eig,
                           lexicon=lexicon_pco,
                           lexicon_ev=lexicon_pcoa$values$Broken_stick,
                           geo=geo_mem)

# Find all factor combinations
factor_names <- c("genetics", "music", "grammar","phonology", "lexicon")
factor_combinations <- get_all_factor_combinations(factor_names)
```


### Setup 0: RDA

In this setup we perform an RDA without controlling for potential confounding factors. We use each of the factors as either the response or the explanatory variable in turns. This yields twelve RDA pairs for which we report the coefficient of determination (adjusted $R^2$) and the significance of the correlation determined by an ANOVA like permutation test. We perform the RDA with $k = 15\%$, i.e. we retain all $k$ PCs/PCos which account for at least 15% of the explained variance.

```{r rda0, cache=T}

# Iterate over all factor combination
rda_setup_0 <- lapply(factor_combinations, function (x) {
  rda_wrapper_setup_0(factors[x[1]][[1]], 
                      factors[x[2]][[1]], n_perm=10000)})
```

We simplify the RDA results and adjust the significance for multiple testing using False Discovery Rate. Finally, we plot the explained variance and significance for each association.

```{r rda0plot, fig.cap='RDA: Variance in the response explained by each explanatory variable;  * indicates a  significant association ($p \\leq 0.05$).', fig.scap='RDA: Variance in the response explained by each explanatory variable', fig.path='figures/', dev='cairo_pdf', cache=T, fig.width=10, fig.height=7, out.extra=''}

rda_correlation_matrix <- rda_to_correlation_matrix(rda_setup_0, adjust_significance=T)
plot_rda_as_matrix(rda_correlation_matrix)

```

We observe two significant associations,  between grammar and genetics on the one hand, and genetics and grammar on the other. We will now explore if these associations hold in a partial RDA, i.e. in an RDA which accounts for the influence of spatial autocorrelation and genealogy.

\clearpage

### Setup 1: Partial RDA controlling for spatial autocorrelation


Next, we perform a partial RDA where we explore the influence of space on the observed associations. Partial RDA removes the effects of one or more explanatory variables on the response prior to an ordinary RDA [@borcard1992partialling]. In our case, the influence of space is removed. Since most languages in the sample occupy relatively large territories (Fig. S1), choosing a central point location might yield a misleading picture of the possible spatial interactions. Instead, we randomly sample 1,000 spatial locations from the language polygons and perform a partial RDA for each. With each sample we remove the influence for one possible scenario of spatial neighborhood or spatial autocorrelation. 

```{r rda1, cache=T}
rda_setup_1 <- lapply(factor_combinations, function (x) {
  rda_wrapper_setup_1(factors[x[1]][[1]], 
                      factors[x[2]][[1]], 
                      factors$geo, n_perm=100)})
# Rename the list entries
names(rda_setup_1) <- sapply(rda_setup_1, function (q){
  return (paste(q[[1]]$explanatory, q[[1]]$response, sep="_"))})
```

We compare the distribution of the adjusted $R^2$ across the 1,000 spatial locations against a distribution of adjusted $R^2$ based on random permutations ($N=100$), i.e. samples for which the rows of the explanatory variable were randomly permuted for each run of the partial RDA.
The two density plots below show the difference between observed and permuted adjusted $R^2$ for the association between genetics and grammar and between grammar and genetics. 

The difference between the observed and the permuted adjusted $R^2$ needs to be statistically evaluated to determine whether the distribution of observed adjusted $R^2$ is likely to produce values equal or larger than the permuted one. To do so, we asses the $z$-score of each sample, defined as $z=\Delta R^2 / \textrm{sd}(R^{2}_{permuted})$, where $\Delta R^2= R_{observed}^2- E[R_{permuted}^2]$ and $R^2$ refers to the adjusted $R^2$. The expected values and standard deviations are estimated on the sample of all $1,000$ randomly sampled spatial location. 

In order to assess how robust the results are across the 1,000 samples we report:

- all samples with strong positive z-scores ($P(z>1 SD)$) i.e. samples, where the observed adjusted $R^2$ is one standard deviation larger than the permuted 
- the Kullback-Leibler divergence (KLD) between the distribution of observed adjusted $R^2$ and permuted adjusted $R^2$. 

The KLD allows to assess the overall divergence of the two distributions and $P(z>1 SD)$ reports the the proportion of (strongly) positive differences. 
\
```{r gengramrda1, fig.cap='Partial RDA controlling for spatial autocorrelation: The association between Genetics (explanatory variable) and Grammar (response). In the figure on the left, the red curve shows the observed (adjusted) $R^2$, the blue curve the $R^2$ for random permutations. In the figure on the right, the green curve shows the difference of $R^2$ (observed - random permutations).', fig.scap='Partial RDA controlling for space: Genetics \u2192 Grammar', fig.path='figures/', dev='cairo_pdf', fig.width=10, fig.height=7, echo=F, cache=T, out.extra=''}

# Genetics --> Grammar 
spatial_density_plot(rda_setup_1$genetics_grammar, "r2_adj_partial", difference=TRUE, rda_title="Partial RDA controlling for spatial autocorrelation:")
```

```{r gramgenrda1, fig.cap='Partial RDA controlling for spatial autocorrelation: The association between Grammar (explanatory variable) and Genetics (response). In the figure on the left, the red curve shows the observed (adjusted) $R^2$, the blue curve the $R^2$ for random permutations. In the figure on the right, the green curve shows the difference of $R^2$ (observed - random permutations).', fig.scap='Partial RDA controlling for space: Grammar \u2192 Genetics',  fig.path='figures/', dev='cairo_pdf', fig.width=10, fig.height=7, message=FALSE, warning=FALSE, echo=F, cache=T, out.extra=''}

# Grammar --> Genetics
spatial_density_plot(rda_setup_1$grammar_genetics, "r2_adj_partial", difference=TRUE, rda_title="Partial RDA controlling for spatial autocorrelation:")

```


```{r, r2means1, cache=T}

rda_setup_1_z <- partial_rda_to_z_val(rda_setup_1, r2_type="r2_adj_partial")
proportion_rda_setup_1 <- add_proportion_and_kld(rda_setup_1_z, 
                                                 diff_th = 1., order_entries=T)
```


```{r ridge1, fig.cap='Partial RDA controlling for spatial autocorrelation: Densities of the difference between observedand permuted adjusted $R^2$ (z-normalized). All input components contribute at least 15\\% to the explained variance. Numbers right to the dashed line show the proportion of samples with a strong positive difference \u2013 $P(z>1$ SD). Grey shading reflects the Kullback-Leibler divergence (KLD) between the observed and permuted adjusted $R^2$. The KLD is transparent for associations where $P(z>0) < 50\\%$.', fig.scap='Partial RDA controlling for space: Densities of all associations',  fig.path='figures/', dev='cairo_pdf', fig.width=10, fig.height=7, message=FALSE, warning=FALSE, echo=F, cache=T, out.extra=''}
association_plot_partial(proportion_rda_setup_1, title="Partial RDA controlling for spatial autocorrelation")

```
\clearpage

```{r kld 1, echo=F}

kld1 <- data.frame(
  assoc= proportion_rda_setup_1$summary$Association[order(proportion_rda_setup_1$summary$kld_disp,
                                                          decreasing = T)],
  kld = round(proportion_rda_setup_1$summary$kld[order(proportion_rda_setup_1$summary$kld_disp, 
                                                 decreasing = T)], 1))
kable(kld1, 
      col.names = c("", "KLD"), 
      format = 'latex', caption="Partial RDA controlling for space: Kullback-Leibler divergence (KLD) between observed and permuted adjusted $R^2$", caption.short = "Partial RDA controlling for space: KLD")

```

\clearpage

### Setup 2: Partial RDA controlling for spatial autocorrelation and genealogy


In addition to space, we now also control for the possible influence of phylogenetic inheritance in the three cases where we have data from the same language families (Even and Evenki from the Tungusic, Selkup and Nganasan from the Uralic, and Koryak and Chukchi from the Chukotko-Kamchatkan family). 

```{r rda2, cache=T}

# Define single languages and family-related languages
single_lgs <- c("Ainu", "Buryat", "Japanese", "Korean", "Nivkh", "West Greenlandic", 
                "Yakut", "Yukagir")
uralic <- c("Selkup", "Nganasan")
chkkat <- c("Chukchi", "Koryak")
tungus <- c("Even", "Evenki")

rda_setup_2 <- lapply(factor_combinations, function (x) {
  rda_wrapper_setup_2(factors[x[1]][[1]], 
                      factors[x[2]][[1]],
                      factors$geo, 
                      n_perm=100)})

# Rename the list entries
names(rda_setup_2) <- sapply(rda_setup_2 , function (q){
  return (paste(q[[1]]$explanatory, q[[1]]$response, sep="_"))})
```


Again, we compare the distribution of the adjusted $R^2$ across the 1,000 spatial locations against the adjusted $R^2$ based on random permutations ($N=100$ per sample). The two density plots below show the difference between observed and permuted adjusted $R^2$ for the association between genetics and grammar and between grammar and genetics. We also statistically evaluate the difference between the observed and the permuted adjusted $R^2$ and visualize it in a ridge plot.


```{r gengramrda2, fig.cap='Partial RDA controlling for spatial autocorrelation and genealogy: The association between Genetics (explanatory variable) and Grammar (response). In the figure on the left, the red curve shows the observed (adjusted) $R^2$, the blue curve the $R^2$ for random permutations. In the figure on the right, the green curve shows the difference of $R^2$ (observed - random permutations).', fig.scap='Partial RDA controlling for space and genealogy: Genetics \u2192 Grammar',fig.path='figures/', dev='cairo_pdf', fig.width=10, fig.height=7, echo=F, cache=T, out.extra=''}

# Genetics --> Grammar 
spatial_density_plot(rda_setup_2$genetics_grammar, "r2_adj_partial", difference=TRUE, genealogy=TRUE, 
                     rda_title="Partial RDA controlling for spatial autocorrelation and genealogy:")
```

```{r gramgenrda2, fig.cap='Partial RDA controlling for spatial autocorrelation and genealogy: The association between Grammar (explanatory variable) and Genetics (response). In the figure on the left, the red curve shows the observed (adjusted) $R^2$, the blue curve the $R^2$ for random permutations. In the figure on the right, the green curve shows the difference of $R^2$ (observed - random permutations).', fig.scap='Partial RDA controlling for space and genealogy: Grammar \u2192 Genetics', fig.path='figures/', dev='cairo_pdf', fig.width=10, fig.height=7, message=FALSE, warning=FALSE, echo=F, cache=T, out.extra=''}

# Grammar --> Genetics
spatial_density_plot(rda_setup_2$grammar_genetics, "r2_adj_partial", difference=TRUE, genealogy=TRUE, rda_title="Partial RDA controlling for spatial autocorrelation and genealogy:")

```



```{r, r2means2, cache=T}

rda_setup_2_z <- partial_rda_to_z_val(rda_setup_2, r2_type="r2_adj_partial")
proportion_rda_setup_2 <- add_proportion_and_kld(rda_setup_2_z, 
                                                 diff_th = 1., order_entries = T)
```


```{r ridge2, echo=F, fig.cap='Partial RDA controlling for spatial autocorrelation and genealogy: Densities of the difference between observed and permuted adjusted $R^2$ (z-normalized) in the partial RDA. All input components contribute at least 15\\% to the explained variance. Numbers right to the dashed line show the proportion of samples with a strong positive difference \u2013 $P(z>1$ SD). Grey shading reflects the Kullback-Leibler divergence (KLD) between the observed and permuted adjusted $R^2$. The KLD is transparent for associations where $P(z>0) < 50\\%$.', fig.scap='Partial RDA controlling for space and genealogy: Densities of all associations', message=F, warning=F, dev='cairo_pdf', fig.path='figures/', fig.width=10, fig.height=7, echo=F, cache=T, out.extra=''} 

association_plot_partial(proportion_rda_setup_2, title="Partial RDA controlling for spatial autocorrelation and genealogy")

```

\clearpage

```{r kld 2, echo=F}

kld2 <- data.frame(
  assoc= proportion_rda_setup_2$summary$Association[order(proportion_rda_setup_2$summary$kld_disp,
                                                          decreasing = T)],
  kld = round(proportion_rda_setup_2$summary$kld[order(proportion_rda_setup_2$summary$kld_disp, 
                                                 decreasing = T)],1))


kable(kld2, 
      col.names = c("", "KLD"), 
      format = 'latex', caption="Partial RDA controlling for space and genealogy: Kullback-Leibler divergence (KLD) between observed and permuted adjusted $R^2$", caption.short = "Partial RDA controlling for space and genealogy: KLD")

```

\clearpage 

## Sensitivity Analysis

### Sensitivity 1: Influence of principal components/coordinates

First we explore to what extent the association between grammar and genetics and genetics and grammar are sensitive to the number of principal components/coordinates used as input. We vary the parameter $k$, which controls the number of PCs/Pcos, such that $k=0.1$, $k=0.15$, and $k=0.18$. The range in which we vary $k$ is given by the data. For $k>0.18$, we risk to have no explanatory variables: grammar does not have components that explain, say,  20% of the variance. For $k<0.1$ we risk to have too many explanatory variables. Both grammar and genetics have many components that explain, say, 5% of the variance. Together with the controls (space, genealogy) the model might be overdetermined, with more variables than observations. As before, we run a partial RDA and account for both spatial autocorrelation and genealogy. 

```{r sens1, eval=T, cache=T}

ks = c(0.1, 0.15, 0.18)

factor_names <- c("genetics", "grammar")
factor_combinations <- get_all_factor_combinations(factor_names)

rda_sens_pc <- list()

for (k in ks) {
  # Retain PCs/PCos which explain at least k%
  factors <- pcos_to_factors(var_th=k, 
                             genetics=genetics_pco, 
                             genetics_ev=genetics_pcoa$values$Rel_corr_eig,
                             grammar=grammar_pc, grammar_ev=grammar_famd$eig[, 2], 
                             phonology=phonology_pc, phonology_ev=phonology_famd$eig[, 2],
                             music=music_pco, music_ev=music_pcoa$values$Rel_corr_eig,
                             lexicon=lexicon_pco, 
                             lexicon_ev=lexicon_pcoa$values$Broken_stick,
                             geo=geo_mem)
  # Run Partial RDA
  rda_result <- lapply(factor_combinations, function (x) {
    rda_wrapper_setup_2 (factors[x[1]][[1]], 
                         factors[x[2]][[1]], 
                         factors$geo,
                         n_perm=100)})

  # Rename the list entries
  names(rda_result) <- sapply(rda_result , function (q){
    return (paste(q[[1]]$explanatory, q[[1]]$response, sep="_"))})
  
  for (n in names(rda_result)){
    rda_sens_pc[[n]][[as.character(k)]] <- rda_result[[n]]
  }} 

```

For each $k$, we statistically evaluate the difference between the observed and the permuted adjusted $R^2$ and visualize it in a ridge plot.

```{r, r2meanssens1, cache=T}

proportion_rda_sens_pc <- list()

for (n in names(rda_sens_pc)){
    z <- partial_rda_to_z_val(rda_sens_pc[[n]], r2_type="r2_adj_partial")
    proportion_rda_sens_pc[[n]] <- add_proportion_and_kld(z, diff_th = 1.)}
    
```

```{r ridgeplot1 sens pc , echo=F, fig.cap='The influence of the number of principal components/coordinates on the association between Genetics (explanatory variable) and Grammar (response). PCs/Pcos must account for at least $k$\\% of the explained variance. Densities of the difference between observed and permuted adjusted $R^2$ (z-normalized) in the partial RDA. Numbers right to the dashed line show the proportion of samples with a strong positive difference \u2013 $P(z>1$ SD). Grey shading reflects the Kullback-Leibler divergence (KLD) between the observed and permuted adjusted $R^2$.', fig.scap='Sensitivity analysis 1: Genetics \u2192 Grammar', message=F, warning=F, dev='cairo_pdf', fig.path='figures/', fig.width=10, fig.height=5, cache=T, echo=F, 'out.extra'=''} 
# Genetics --> Grammar 
association_plot_partial(proportion_rda_sens_pc$genetics_grammar, k=T, title="Influence of Principal components/coordinates: Genetics \u2192 Grammar")

```

\clearpage

```{r ridgesens1 , echo=F, fig.cap='The influence of the number of principal components/coordinates on the association between Grammar (explanatory variable) and Genetics (response). PCs/Pcos must account for at least $k$\\% of the explained variance. Densities of the difference between observed and permuted adjusted $R^2$ values (z-normlalized) in the partial RDA.  Numbers right to the dashed line show the proportion of samples with a strong positive difference \u2013 $P(z>1$ SD). Grey shading reflects the Kullback-Leibler divergence (KLD) between the observed and permuted adjusted $R^2$.', fig.scap='Sensitivity analysis 1: Grammar \u2192 Genetics', message=F, warning=F, dev='cairo_pdf', fig.path='figures/', fig.width=10, fig.height=5, cache=T, echo=F, out.extra=''} 
# Grammar --> Genetics
association_plot_partial(proportion_rda_sens_pc$grammar_genetics, k=T, title="Influence of Principal components/coordinates: Grammar \u2192 Genetics")
```



```{r kld pc2, echo=F}

kld_pc <- data.frame(
  assoc1= rownames(proportion_rda_sens_pc$genetics_grammar$summary),
  kld1 = round(proportion_rda_sens_pc$genetics_grammar$summary$kld, 1),
  assoc2= rownames(proportion_rda_sens_pc$grammar_genetics$summary),
  kld2 = round(proportion_rda_sens_pc$grammar_genetics$summary$kld, 1))


k_pc <- kable(kld_pc, 
      col.names = c("k", "KLD", "k", "KLD"),
      format = 'latex', 
      caption="Influence of Principal components/coordinates: Kullback-Leibler divergence (KLD)",
      caption.short = "Sensitivity analysis 1: KLD")

add_header_above(k_pc, header=c("Genetics --> Grammar"=2, "Grammar --> Genetics"= 2))

```

\clearpage

### Sensitivity 2: Influence of single societies

We explore the influence of sampling on the model. Some societies  might have a larger effect on the associations than others. We exclude each society in turn and run a partial RDA. We control for spatial autocorrelation and both spatial autocorrelation and genealogy.

```{r, sens2, cache=T}
rda_sens_sites_1 <- list()
rda_sens_sites_2 <- list()

factors <- pcos_to_factors(var_th=0.15, 
                           genetics=genetics_pco, 
                           genetics_ev=genetics_pcoa$values$Rel_corr_eig,
                           grammar=grammar_pc, grammar_ev=grammar_famd$eig[, 2], 
                           phonology=phonology_pc, phonology_ev=phonology_famd$eig[, 2], 
                           music=music_pco, music_ev=music_pcoa$values$Rel_corr_eig,
                           lexicon=lexicon_pco, 
                           lexicon_ev=lexicon_pcoa$values$Broken_stick,
                           geo=geo_mem)
```


```{r, rdasens2spat, cache=T}

for (l in languages) {
   
  rda_result_1 <- lapply(factor_combinations, function (x) {
    rda_wrapper_sensitivity_1(factors[x[1]][[1]],
                              factors[x[2]][[1]],
                              exclude_site=l,
                              factors$geo, n_perm=100)})
  

  # Rename the list entries
  names(rda_result_1) <- sapply(rda_result_1 , function (q){
    return (paste(q[[1]]$explanatory, q[[1]]$response, sep="_"))})


  
  for (n in names(rda_result_1)){
    rda_sens_sites_1[[n]][[as.character(l)]] <- rda_result_1[[n]]}

  
  rda_sens_sites_1[["n_sites"]][[as.character(l)]] <- rda_result_1[[1]][[1]]$n_sites
} 


```


```{r, rdasens2spatgen, cache=T}

for (l in languages) {
   
  rda_result_2 <- lapply(factor_combinations, function (x) {
    rda_wrapper_sensitivity_2(factors[x[1]][[1]],
                               factors[x[2]][[1]],
                               exclude_site=l,
                               factors$geo, n_perm=100)})

  # Rename the list entries
  names(rda_result_2) <- sapply(rda_result_2 , function (q){
    return (paste(q[[1]]$explanatory, q[[1]]$response, sep="_"))})
  
  for (n in names(rda_result_2)){
    rda_sens_sites_2[[n]][[as.character(l)]] <- rda_result_2[[n]]}
  

  rda_sens_sites_2[["n_sites"]][[as.character(l)]] <- rda_result_2[[1]][[1]]$n_sites
} 


```

For each society removed we statistically evaluate the difference between the observed and permuted adjusted $R^2$ and visualize it in a ridge plot.

```{r, r2meanssens2, cache=T}

proportion_rda_sens_sites_1<- list()
proportion_rda_sens_sites_2 <- list()


for (n in names(rda_sens_sites_1)[names(rda_sens_sites_1) != "n_sites"]){
    z <- partial_rda_to_z_val(rda_sens_sites_1[[n]], r2_type="r2_adj_partial")
    proportion_rda_sens_sites_1[[n]] <- add_proportion_and_kld(z, diff_th = 1., order_entries=T)}

for (n in names(rda_sens_sites_2)[names(rda_sens_sites_2) != "n_sites"]){
    z <- partial_rda_to_z_val(rda_sens_sites_2[[n]], r2_type="r2_adj_partial")
    proportion_rda_sens_sites_2[[n]] <- add_proportion_and_kld(z, diff_th=1., order_entries = T)}
    
```


```{r ridge1sens2gengra, echo=F, fig.cap='The influence of single societies on the association between Genetics (explanatory variable) and Grammar (response). Densities of the difference between observed and permuted adjusted $R^2$ (z-normalized) in the partial RDA controlling for space but not for genealogy. Numbers right to the dashed line show the proportion of samples with a strong positive difference \u2013 $P(z>1$ SD). Grey shading reflects the Kullback-Leibler divergence (KLD) between the observed and permuted adjusted $R^2$.', message=F, warning=F, fig.scap='Sensitivity analysis 2: Genetics \u2192 Grammar (controlling for space)',  dev='cairo_pdf', fig.path='figures/', fig.width=10, fig.height=7, cache=T, echo=F,out.extra=''}
# Genetics --> Grammar 
association_plot_partial(proportion_rda_sens_sites_1$genetics_grammar, n_sites=rda_sens_sites_1$n_sites, title="Removing societies in a partial RDA controlling for space: Genetics \u2192 Grammar")
```


```{r ridge1sens2gragen, echo=F, fig.cap='The influence of potential outlier societies on the association between Grammar (explanatory variable) and Genetics (response). Densities of the difference between observed and permuted adjusted $R^2$ (z-normalized) in the partial RDA controlling for space but not for genealogy. Numbers right to the dashed line show the proportion of samples witha strong positive difference \u2013 $P(z>1$ SD). Grey shading reflects the Kullback-Leibler divergence (KLD) between the observed and permuted adjusted $R^2$.', fig.scap='Sensitivity analysis 2: Grammar \u2192 Genetics (controlling for space)', message=F, warning=F, dev='cairo_pdf', fig.path='figures/', fig.width=10, fig.height=7, out.extra=''}

association_plot_partial(proportion_rda_sens_sites_1$grammar_genetics, n_sites=rda_sens_sites_1$n_sites, title="Removing societies in a partial RDA controlling for space: Grammar \u2192 Genetics")
```


```{r kld sens1, echo=F}


kld_sens1 <- data.frame(
  assoc1= paste0(rownames(proportion_rda_sens_sites_1$genetics_grammar$summary)
                         [order(proportion_rda_sens_sites_2$genetics_grammar$summary$kld,
                                decreasing = T)], " removed"),
  kld1 = round(proportion_rda_sens_sites_1$genetics_grammar$summary$kld
  [order(proportion_rda_sens_sites_2$genetics_grammar$summary$kld,
         decreasing = T)],1),
  assoc2= paste0(rownames(proportion_rda_sens_sites_1$grammar_genetics$summary)
                         [order(proportion_rda_sens_sites_1$grammar_genetics$summary$kld,
                                decreasing = T)], " removed"),
  kld2 = round(proportion_rda_sens_sites_1$grammar_genetics$summary$kld
  [order(proportion_rda_sens_sites_1$grammar_genetics$summary$kld,
         decreasing = T)], 1))

                                               
k_sens1 <- kable(kld_sens1, 
      col.names = c("", "KLD", "", "KLD"), 
      format = 'latex', caption="Influence of outlier societies: Kullback-Leibler divergence (KLD) (controlling for space)", caption.short = "Sensitivity analysis 2: KLD (controlling for space)")


add_header_above(k_sens1, header=c("Genetics --> Grammar"=2, "Grammar --> Genetics"= 2))


```

\clearpage

```{r ridge2sens2gengra, echo=F, fig.cap='The influence of potential outlier societies on the association between Genetics (explanatory variable) and Grammar (response). Densities of the difference between observed and permuted adjusted $R^2$ (z-normalized) in the partial RDA controlling for space and for genealogy. Numbers right to the dashed line show the proportion of samples with a strong positive difference \u2013 $P(z>1$ SD). Grey shading reflects the Kullback-Leibler divergence (KLD) between the observed and permuted adjusted $R^2$.', fig.scap='Sensitivity analysis 2: Genetics \u2192 Grammar (controlling for space and genealogy)', message=F, warning=F, dev='cairo_pdf', fig.path='figures/', fig.width=10, fig.height=7, cache=T, echo=F, out.extra=''}
# Genetics --> Grammar 
association_plot_partial(proportion_rda_sens_sites_2$genetics_grammar, n_sites=rda_sens_sites_2$n_sites, title="Removing societies in a partial RDA controlling for space and genealogy: Genetics \u2192 Grammar")

```


```{r ridge2sens2gragen, echo=F, fig.cap='The influence of potential outlier societies on the association between Grammar (explanatory variable) and Genetics (response). Densities of the difference between observed and permuted adjusted $R^2$ (z-normalized) in the partial RDA. Numbers right to the dashed line show the proportion of samples with a strong positive difference \u2013 $P(z>1$ SD). Grey shading reflects the Kullback-Leibler divergence (KLD) between the observed and permuted adjusted $R^2$.', fig.scap='Sensitivity analysis 2: Grammar \u2192 Genetics (controlling for space and genealogy)', message=F, warning=F, dev='cairo_pdf', fig.path='figures/', fig.width=10, fig.height=7, cache=T, echo=F, out.extra=''}
# Grammar --> Genetics
association_plot_partial(proportion_rda_sens_sites_2$grammar_genetics, n_sites=rda_sens_sites_2$n_sites, title="Removing societies in a partial RDA controlling for space and genealogy: Grammar \u2192 Genetics")

```


```{r kld sens2, echo=F}


kld_sens2 <- data.frame(
  assoc1= paste0(rownames(proportion_rda_sens_sites_2$genetics_grammar$summary)
                         [order(proportion_rda_sens_sites_2$genetics_grammar$summary$kld,
                                decreasing = T)], " removed"),
  kld1 = round(proportion_rda_sens_sites_2$genetics_grammar$summary$kld
  [order(proportion_rda_sens_sites_2$genetics_grammar$summary$kld,
         decreasing = T)],1),
  assoc2= paste0(rownames(proportion_rda_sens_sites_2$grammar_genetics$summary)
                         [order(proportion_rda_sens_sites_2$grammar_genetics$summary$kld,
                                decreasing = T)], " removed"),
  kld2 = round(proportion_rda_sens_sites_2$grammar_genetics$summary$kld
  [order(proportion_rda_sens_sites_2$grammar_genetics$summary$kld,
         decreasing = T)],1))

                                               
k_sens2 <- kable(kld_sens2, 
      col.names = c("", "KLD", "", "KLD"), 
      format = 'latex', caption="Influence of outlier societies: Kullback-Leibler divergence (KLD) (controlling for space and genealogy)", caption.short = "Sensitivity analysis 2: KLD (controlling for space and genealogy)")


add_header_above(k_sens2, header=c("Genetics --> Grammar"=2, "Grammar --> Genetics"= 2))


```

\clearpage 


### Sensitivity 3: Spatial distribution of $R^2$

Spatial neighborhood is unlikely to explain the observed relationship between factors if the adjusted $R^2$ for all spatial locations is well above zero and if it differs from the adjusted $R^2$ under random permutations, both of which we have shown above. However, the correlations we find might still be an artifact of space. When sampling locations for languages spoken in a large area, there will necessary be locations that are far from each other.

If two societies have been in contact and this is the reason for their similarities, then there will be a spatial configuration that reflects this.  This means that samples in a specific spatial area (i.e. a contact area) will have a low adjusted $R^2$ and hence report a low association between grammar and genes after controlling for spatial neighborhood. To rule this out, we map all samples for which the adjusted $R^2$ is in the 0.2 percentile and analyze the spatial pattern. Figures S30 and S31 suggest that for both associations locations with low adjusted $R^2$ randomly distribute in the polygons and do not mass up in specific regions.


```{r lowrdagengram, fig.cap='Location samples used for removing the influence of space in the partial RDA between Genetics (explanatory variable) and Grammar (response) with a low adjusted $R^2$', fig.scap='Sensitivity analysis 3: Genetics \u2192 Grammar (locations with low $R^2$)', fig.path='figures/', dev='cairo_pdf', fig.width=10, fig.height=7, echo=F, cache=T, fig.pos='H', out.extra=''}

# Genetics --> Grammar 
low_loc_1_gen_grammar <- map_r2(rda_setup_2$genetics_grammar, geo_random_points, 
                                geo_polygons_map, languages_1, lang_labels, 
                                "r2_adj_semi", 0.2, below_thr = T,lang_color = colors_1,
                                title="Locations with low adjusted R squared: Genetics \u2192 Grammar")
low_loc_2_gen_grammar <- map_r2(rda_setup_2$genetics_grammar, geo_random_points, 
                                geo_polygons_map, languages_2, lang_labels, 
                                "r2_adj_semi", 0.2, below_thr = T, lang_color = colors_2, 
                                title="")

plot_grid(ggplotGrob(low_loc_1_gen_grammar), ggplotGrob(low_loc_2_gen_grammar))

```

```{r lowrdagramgen, fig.cap='Location samples used for removing the influence of space in the partial RDA between Grammar (explanatory variable) and Genetics (response) with a low adjusted $R^2$', fig.scap='Sensitivity analysis 3: Grammar \u2192 Genetics (locations with low $R^2$ )', fig.path='figures/', dev='cairo_pdf', fig.width=10, fig.height=7, echo=F, cache=T, fig.pos='H', out.extra=''}

# Grammar --> Genetics 
low_loc_1_grammar_gen  <- map_r2(rda_setup_2$grammar_genetics, geo_random_points, 
                                 geo_polygons_map, languages_1, lang_labels, 
                                 "r2_adj_semi", 0.2, below_thr = T, lang_color = colors_1, 
                                 title="Locations with low adjusted R squared: Grammar \u2192 Genetics")
low_loc_2_grammar_gen <- map_r2(rda_setup_2$grammar_genetics, geo_random_points, 
                                geo_polygons_map, languages_2, lang_labels, 
                                "r2_adj_semi", 0.2, below_thr = T, lang_color = colors_2,
                                title="")

plot_grid(ggplotGrob(low_loc_1_grammar_gen), ggplotGrob(low_loc_2_grammar_gen))

```


We also plot locations with high adjusted $R^2$ (0.8 percentile) to check for the other extreme that only some spatial configurations result in strong associations. This would imply that in most samples spatial neighborhood explains the similarities, but there are some systematic outliers where this is not the case, which ultimately yield the signal that we pick up. While we see weak clustering in Evenki, Buryat and Selkup, this is not the case for any of the other languages.


```{r highrdagengram, fig.cap='Location samples used for removing the influence of space in the partial RDA between Genetics (explanatory variable) and Grammar (response) with a high adjusted $R^2$', fig.scap='Sensitivity analysis 3: Genetics \u2192 Grammar (locations with high $R^2$)', fig.path='figures/', dev='cairo_pdf', fig.width=10, fig.height=7, echo=F, cache=T, fig.pos='H', out.extra=''}

# Genetics --> Grammar 
high_loc_1_gen_grammar  <- map_r2(rda_setup_2$genetics_grammar, geo_random_points, 
                                 geo_polygons_map, languages_1, lang_labels, 
                                 "r2_adj_semi", 0.8, below_thr = F,lang_color = colors_1,
                                 title="Locations with high adjusted R squared: Genetics \u2192 Grammar")
high_loc_2_gen_grammar <- map_r2(rda_setup_2$genetics_grammar, geo_random_points, 
                                 geo_polygons_map, languages_2, lang_labels, 
                                 "r2_adj_semi", 0.8, below_thr = F, lang_color = colors_2, title="")

plot_grid(ggplotGrob(high_loc_1_gen_grammar), ggplotGrob(high_loc_2_gen_grammar))

```


```{r highrdagramgen, fig.cap='Location samples used for removing the influence of space in the partial RDA between Grammar (explanatory variable) and Genetics (response) with a high adjusted $R^2$', fig.scap='Sensitivity analysis 3: Grammar \u2192 Genetics (locations with high $R^2$)', fig.path='figures/', dev='cairo_pdf', fig.width=10, fig.height=7, echo=F, cache=T, fig.pos='H', out.extra=''}

# Grammar --> Genetics 
high_loc_1_grammar_gen  <- map_r2(rda_setup_2$grammar_genetics, geo_random_points, 
                                 geo_polygons_map, languages_1, lang_labels, 
                                 "r2_adj_semi", 0.8, below_thr = F, lang_color = colors_1, 
                                 title="Locations with high adjusted R squared: Grammar \u2192 Genetics")
high_loc_2_grammar_gen <- map_r2(rda_setup_2$grammar_genetics, geo_random_points, 
                                geo_polygons_map, languages_2, lang_labels, 
                                "r2_adj_semi", 0.8, below_thr = F, lang_color = colors_2, title="")

plot_grid(ggplotGrob(high_loc_1_grammar_gen), ggplotGrob(high_loc_2_grammar_gen))

```


Taken together, there is neither evidence for recent contact explaining the associations (low adjusted $R^2$ clustering in space) nor evidence for systematic spatial outliers influencing the signal (high adjusted $R^2$ clustering in space). 

\clearpage

# References

